{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| name: '!Якутск Орджоникидзе, 56 фран'\n",
      "ic| name: '!Якутск ТЦ \"Центральный\" фран'\n",
      "ic| name: 'Адыгея ТЦ \"Мега\"'\n",
      "ic| name: 'Балашиха ТРК \"Октябрь-Киномир\"'\n",
      "ic| name: 'Волжский ТЦ \"Волга Молл\"'\n",
      "ic| name: 'Вологда ТРЦ \"Мармелад\"'\n",
      "ic| name: 'Воронеж (Плехановская, 13)'\n",
      "ic| name: 'Воронеж ТРЦ \"Максимир\"'\n",
      "ic| name: 'Воронеж ТРЦ Сити-Парк \"Град\"'\n",
      "ic| name: 'Выездная Торговля'\n",
      "ic| name: 'Жуковский ул. Чкалова 39м?'\n",
      "ic| name: 'Жуковский ул. Чкалова 39м²'\n",
      "ic| name: 'Интернет-магазин ЧС'\n",
      "ic| name: 'Казань ТЦ \"Бехетле\"'\n",
      "ic| name: 'Казань ТЦ \"ПаркХаус\" II'\n",
      "ic| name: 'Калуга ТРЦ \"XXI век\"'\n",
      "ic| name: 'Коломна ТЦ \"Рио\"'\n",
      "ic| name: 'Красноярск ТЦ \"Взлетка Плаза\"'\n",
      "ic| name: 'Красноярск ТЦ \"Июнь\"'\n",
      "ic| name: 'Курск ТЦ \"Пушкинский\"'\n",
      "ic| name: 'Москва \"Распродажа\"'\n",
      "ic| name: 'Москва МТРЦ \"Афи Молл\"'\n",
      "ic| name: 'Москва Магазин С21'\n",
      "ic| name: 'Москва ТК \"Буденовский\" (пав.А2)'\n",
      "ic| name: 'Москва ТК \"Буденовский\" (пав.К7)'\n",
      "ic| name: 'Москва ТРК \"Атриум\"'\n",
      "ic| name: 'Москва ТЦ \"Ареал\" (Беляево)'\n",
      "ic| name: 'Москва ТЦ \"МЕГА Белая Дача II\"'\n",
      "ic| name: 'Москва ТЦ \"МЕГА Теплый Стан\" II'\n",
      "ic| name: 'Москва ТЦ \"Новый век\" (Новокосино)'\n",
      "ic| name: 'Москва ТЦ \"Перловский\"'\n",
      "ic| name: 'Москва ТЦ \"Семеновский\"'\n",
      "ic| name: 'Москва ТЦ \"Серебряный Дом\"'\n",
      "ic| name: 'Мытищи ТРК \"XL-3\"'\n",
      "ic| name: 'Н.Новгород ТРЦ \"РИО\"'\n",
      "ic| name: 'Н.Новгород ТРЦ \"Фантастика\"'\n",
      "ic| name: 'Новосибирск ТРЦ \"Галерея Новосибирск\"'\n",
      "ic| name: 'Новосибирск ТЦ \"Мега\"'\n",
      "ic| name: 'Омск ТЦ \"Мега\"'\n",
      "ic| name: 'РостовНаДону ТРК \"Мегацентр Горизонт\"'\n",
      "ic| name: 'РостовНаДону ТРК \"Мегацентр Горизонт\" Островной'\n",
      "ic| name: 'РостовНаДону ТЦ \"Мега\"'\n",
      "ic| name: 'СПб ТК \"Невский Центр\"'\n",
      "ic| name: 'СПб ТК \"Сенная\"'\n",
      "ic| name: 'Самара ТЦ \"Мелодия\"'\n",
      "ic| name: 'Самара ТЦ \"ПаркХаус\"'\n",
      "ic| name: 'Сергиев Посад ТЦ \"7Я\"'\n",
      "ic| name: 'Сургут ТРЦ \"Сити Молл\"'\n",
      "ic| name: 'Томск ТРЦ \"Изумрудный Город\"'\n",
      "ic| name: 'Тюмень ТРЦ \"Кристалл\"'\n",
      "ic| name: 'Тюмень ТЦ \"Гудвин\"'\n",
      "ic| name: 'Тюмень ТЦ \"Зеленый Берег\"'\n",
      "ic| name: 'Уфа ТК \"Центральный\"'\n",
      "ic| name: 'Уфа ТЦ \"Семья\" 2'\n",
      "ic| name: 'Химки ТЦ \"Мега\"'\n",
      "ic| name: 'Цифровой склад 1С-Онлайн'\n",
      "ic| name: 'Чехов ТРЦ \"Карнавал\"'\n",
      "ic| name: 'Якутск Орджоникидзе, 56'\n",
      "ic| name: 'Якутск ТЦ \"Центральный\"'\n",
      "ic| name: 'Ярославль ТЦ \"Альтаир\"'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from icecream import ic\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from itertools import product\n",
    "from icecream import ic\n",
    "\n",
    "# a = np.arange(0, 35)\n",
    "# ic(a % 12)\n",
    "# ic(a % 13)\n",
    "# exit()\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "sales_train = pd.read_csv('./data/sales_train.csv')\n",
    "test = pd.read_csv('./data/test.csv')   # (214200, 3)\n",
    "\n",
    "# 计算每个商品每个月的销售量，假如某个商品在某个月没有数据，则填充0（即这个月的销售量为0）\n",
    "sales_by_item_id = sales_train.pivot_table(index=['item_id'], values=['item_cnt_day'], columns='date_block_num', aggfunc=np.sum, fill_value=0).reset_index()\n",
    "sales_by_item_id.columns = sales_by_item_id.columns.droplevel().map(str)\n",
    "sales_by_item_id.columns.values[0] = 'item_id'\n",
    "sales_by_item_id = sales_by_item_id.rename_axis(None, axis=1)\n",
    "\n",
    "# 获取最近6个月销售量为0的数据\n",
    "# six_zero = sales_by_item_id[(sales_by_item_id['28'] == 0) & (sales_by_item_id['29'] == 0) & (sales_by_item_id['30'] == 0) & (sales_by_item_id['31'] == 0) & (sales_by_item_id['32'] == 0) & (sales_by_item_id['33'] == 0)]\n",
    "# six_zero_item_id = list(six_zero['item_id'].values)   # item_id列表\n",
    "# test.loc[test.item_id.isin(six_zero_item_id), 'item_cnt_month'] = 0  # 将test数据中（最近六个月销量为0）的数据月销量设为0，有7812个\n",
    "\n",
    "# 计算每个商店每个月的销量\n",
    "sales_by_shop_id = sales_train.pivot_table(index=['shop_id'], values=['item_cnt_day'], aggfunc=np.sum, fill_value=0, columns='date_block_num').reset_index()\n",
    "sales_by_shop_id.columns = sales_by_shop_id.columns.droplevel().map(str)    # 将两层column转化为一层column,保留下层column\n",
    "sales_by_shop_id.columns.values[0] = 'shop_id'\n",
    "sales_by_shop_id = sales_by_shop_id.rename_axis(None, axis=1)   # 将列方向的轴重命名为none\n",
    "\n",
    "# zero = sales_train[sales_train.date_block_num==0]\n",
    "# ic(zero.shop_id.unique(), len(zero.item_id.unique()), len(zero.shop_id.unique()), len(zero.shop_id.unique()) * len(zero.item_id.unique()))\n",
    "# ic(sales_train.shop_id.unique(), len(sales_train.item_id.unique()), len(sales_train.shop_id.unique()), len(sales_train.shop_id.unique()) * len(sales_train.item_id.unique()))\n",
    "\n",
    "\"\"\"组合date_block_num,shop_id,item_id(部分) 总量：10913850\"\"\"\n",
    "matrix = []\n",
    "cols = ['date_block_num','shop_id','item_id']\n",
    "for i in range(34):\n",
    "    sales = sales_train[sales_train.date_block_num==i]\n",
    "    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n",
    "matrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n",
    "matrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\n",
    "matrix['shop_id'] = matrix['shop_id'].astype(np.int8)\n",
    "matrix.sort_values(cols, inplace=True)  # 排序\n",
    "sales_train['revenue'] = sales_train['item_price'] * sales_train['item_cnt_day']    # 某一天的销售额\n",
    "\n",
    "# 分组\n",
    "groupby = sales_train.groupby(['shop_id','item_id','date_block_num']).agg({'item_cnt_day': 'sum'}).reset_index()\n",
    "groupby = groupby.rename(columns={'item_cnt_day': 'item_cnt_month'})\n",
    "matrix = matrix.merge(groupby, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "matrix['item_cnt_month'] = matrix['item_cnt_month'].fillna(0).clip(0, 20)\n",
    "matrix['item_cnt_month'] = matrix['item_cnt_month'].astype(np.float16)\n",
    "\n",
    "# test数据\n",
    "test['date_block_num'] = 34\n",
    "test['date_block_num'] = test['date_block_num'].astype(np.int8)\n",
    "test['shop_id'] = test['shop_id'].astype(np.int8)\n",
    "test['item_id'] = test['item_id'].astype(np.int16)\n",
    "\n",
    "# 合并matrix,test\n",
    "matrix = pd.concat([matrix, test[cols]], ignore_index=True, axis=0)\n",
    "matrix['item_cnt_month'].fillna(0, inplace=True)\n",
    "\n",
    "# 商品信息\n",
    "items = pd.read_csv('./data/items.csv')\n",
    "items = items[['item_id', 'item_category_id']]\n",
    "matrix = pd.merge(left=matrix, right=items, on='item_id', how='left')  # 合并\n",
    "\n",
    "# 商品类别\n",
    "le = LabelEncoder()\n",
    "categories = pd.read_csv('./data/item_categories.csv')\n",
    "categories['split'] = categories['item_category_name'].str.split('-')\n",
    "categories['type'] = categories['split'].map(lambda x:x[0].strip())\n",
    "categories['subtype'] = categories['split'].map(lambda x:x[1].strip() if len(x)>1 else x[0].strip())\n",
    "categories = categories[['item_category_id','type','subtype']]\n",
    "categories['cat_type_code'] = le.fit_transform(categories['type'])\n",
    "categories['cat_subtype_code'] = le.fit_transform(categories['subtype'])\n",
    "matrix = pd.merge(left=matrix, right=categories[['item_category_id','cat_type_code','cat_subtype_code']], on='item_category_id', how='left')    # 合并\n",
    "\n",
    "# 商店信息\n",
    "shops = pd.read_csv('./data/shops.csv')\n",
    "shops['split']=shops.shop_name.str.split(' ')\n",
    "shops['shop_city'] = shops['split'].map(lambda x:x[0])\n",
    "shops['shop_city_code'] = le.fit_transform(shops['shop_city'])\n",
    "\n",
    "def st(name):\n",
    "    ic(name)\n",
    "    if 'ТЦ' in name or 'ТРЦ' in name:\n",
    "        shopt = 'ТЦ'\n",
    "    elif 'ТК' in name:\n",
    "        shopt = 'ТК'\n",
    "    elif 'ТРК' in name:\n",
    "        shopt = 'ТРК'\n",
    "    elif 'МТРЦ' in name:\n",
    "        shopt = 'МТРЦ'\n",
    "    else:\n",
    "        shopt = 'UNKNOWN'\n",
    "    return shopt\n",
    "shops['shop_type'] = shops['shop_name'].apply(st)\n",
    "\n",
    "shops.loc[shops.shop_id == 21, 'shop_type'] = 'МТРЦ'   # 修正\n",
    "shops['shop_type_code'] = le.fit_transform(shops['shop_type'])\n",
    "matrix = pd.merge(left=matrix, right=shops[['shop_id','shop_city_code','shop_type_code']], on='shop_id', how='left')    # 合并\n",
    "matrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\n",
    "matrix['cat_type_code'] = matrix['cat_type_code'].astype(np.int8)\n",
    "matrix['cat_subtype_code'] = matrix['cat_subtype_code'].astype(np.int8)\n",
    "matrix['shop_city_code'] = matrix['shop_city_code'].astype(np.int8)\n",
    "matrix['shop_type_code'] = matrix['shop_type_code'].astype(np.int8)\n",
    "\n",
    "\n",
    "\"\"\"历史信息\"\"\"\n",
    "\n",
    "def lag_features(df, lags, col):\n",
    "    tmp = df[['date_block_num','shop_id','item_id',col]]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['date_block_num','shop_id','item_id',col+'_lag_'+str(i)]\n",
    "        shifted['date_block_num'] = shifted['date_block_num'] + i\n",
    "        df = pd.merge(left=df, right=shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "    return df\n",
    "\n",
    "matrix = lag_features(matrix, [1,2,3,6,12], 'item_cnt_month')\n",
    "\n",
    "# 月销量（所有商品）\n",
    "group = matrix.groupby('date_block_num').agg({'item_cnt_month': 'mean'}).reset_index()\n",
    "group.columns = ['date_block_num', 'date_avg_item_cnt']\n",
    "matrix = pd.merge(left=matrix, right=group, on='date_block_num', how='left')\n",
    "matrix = lag_features(matrix, [1,2,3,6,12], 'date_avg_item_cnt')\n",
    "matrix.drop('date_avg_item_cnt', axis=1, inplace=True)\n",
    "\n",
    "# 月销量（每一件商品）\n",
    "group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "matrix = pd.merge(left=matrix, right=group, on=['date_block_num','item_id'], how='left')\n",
    "matrix = lag_features(matrix, [1,2,3,6,12], 'date_item_avg_item_cnt')\n",
    "matrix.drop('date_item_avg_item_cnt', axis=1, inplace=True)\n",
    "\n",
    "# 月销量（每个商店 ）\n",
    "group = matrix.groupby(['date_block_num','shop_id']).agg({'item_cnt_month': 'mean'})\n",
    "group.columns = ['date_shop_avg_item_cnt']\n",
    "group = group.reset_index()\n",
    "matrix = pd.merge(left=matrix, right=group, on=['date_block_num','shop_id'], how='left')\n",
    "matrix = lag_features(matrix, [1,2,3,6,12], 'date_shop_avg_item_cnt')\n",
    "matrix.drop('date_shop_avg_item_cnt', axis=1, inplace=True)\n",
    "\n",
    "# 月销量（每个类别）\n",
    "group = matrix.groupby(['date_block_num','item_category_id']).agg({'item_cnt_month': 'mean'})\n",
    "group.columns = ['date_cat_avg_item_cnt']\n",
    "group = group.reset_index()\n",
    "matrix=pd.merge(left=matrix, right=group, on=['date_block_num','item_category_id'], how='left')\n",
    "matrix = lag_features(matrix, [1,2,3,6,12], 'date_cat_avg_item_cnt')\n",
    "matrix.drop('date_cat_avg_item_cnt', axis=1, inplace=True)\n",
    "\n",
    "# 月销量（商品类别-商店）\n",
    "group = matrix.groupby(['date_block_num','item_category_id','shop_id']).agg({'item_cnt_month': 'mean'})\n",
    "group.columns = ['date_cat_shop_avg_item_cnt']\n",
    "group = group.reset_index()\n",
    "matrix = pd.merge(left=matrix, right=group, on=['date_block_num','item_category_id','shop_id'], how='left')\n",
    "matrix = lag_features(matrix, [1,2,3,6,12], 'date_cat_shop_avg_item_cnt')\n",
    "matrix.drop('date_cat_shop_avg_item_cnt', axis=1, inplace=True)\n",
    "\n",
    "# 月销量（商品大类）\n",
    "group = matrix.groupby(['date_block_num','cat_type_code']).agg({'item_cnt_month': 'mean'})\n",
    "group.columns = ['date_type_avg_item_cnt']\n",
    "group = group.reset_index()\n",
    "matrix = pd.merge(left=matrix, right=group, on=['date_block_num','cat_type_code'], how='left')\n",
    "matrix = lag_features(matrix, [1,2,3,6,12], 'date_type_avg_item_cnt')\n",
    "matrix.drop('date_type_avg_item_cnt', axis=1, inplace=True)\n",
    "\n",
    "# 月销量（商品-商品大类） ++++++++++++ 和 月销量（商品）是重复的，因为每一个商品，类别是确定的，大类也是确定的\n",
    "group = matrix.groupby(['date_block_num', 'item_id', 'cat_type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_item_type_avg_item_cnt']\n",
    "group = group.reset_index()\n",
    "matrix = pd.merge(left=matrix, right=group, on=['date_block_num', 'item_id', 'cat_type_code'], how='left')\n",
    "matrix = lag_features(matrix, [1,2,3,6,12], 'date_item_type_avg_item_cnt')\n",
    "matrix.drop('date_item_type_avg_item_cnt', axis=1, inplace=True)\n",
    "\n",
    "# 月销量（商店城市）\n",
    "group = matrix.groupby(['date_block_num','shop_city_code']).agg({'item_cnt_month': 'mean'})\n",
    "group.columns = ['date_city_avg_item_cnt']\n",
    "group = group.reset_index()\n",
    "matrix = pd.merge(left=matrix, right=group, on=['date_block_num','shop_city_code'], how='left')\n",
    "matrix = lag_features(matrix, [1,2,3,6,12], 'date_city_avg_item_cnt')\n",
    "matrix.drop('date_city_avg_item_cnt', axis=1, inplace=True)\n",
    "\n",
    "# 月销量（商品-商店城市）\n",
    "group = matrix.groupby(['date_block_num', 'item_id', 'shop_city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_item_city_avg_item_cnt']\n",
    "group = group.reset_index()\n",
    "matrix=pd.merge(left=matrix, right=group, on=['date_block_num', 'item_id', 'shop_city_code'], how='left')\n",
    "matrix = lag_features(matrix, [1,2,3,6,12], 'date_item_city_avg_item_cnt')\n",
    "matrix.drop('date_item_city_avg_item_cnt', axis=1, inplace=True)\n",
    "\n",
    "# 趋势特征\n",
    "group = sales_train.groupby('item_id').agg({'item_price': 'mean'})\n",
    "group.columns = ['item_avg_item_price']\n",
    "group = group.reset_index()\n",
    "matrix = pd.merge(left=matrix, right=group, on='item_id', how='left')\n",
    "\n",
    "group = sales_train.groupby(['date_block_num','item_id']).agg({'item_price': 'mean'})\n",
    "group.columns = ['date_item_avg_item_price']\n",
    "group = group.reset_index()\n",
    "matrix=pd.merge(left=matrix, right=group, on=['date_block_num','item_id'], how='left')\n",
    "\n",
    "matrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)\n",
    "matrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)\n",
    "\n",
    "# 计算matrix中商品的历史价格\n",
    "lags = [1,2,3,4,5,6,12]\n",
    "matrix = lag_features(matrix, lags, 'date_item_avg_item_price')\n",
    "for i in lags:\n",
    "    matrix['delta_price_lag_'+str(i)]=(matrix['date_item_avg_item_price_lag_' + str(i)] - matrix['item_avg_item_price']) / matrix['item_avg_item_price']\n",
    "\n",
    "def select_trend(row):\n",
    "    for i in lags:\n",
    "        if pd.notnull(row['delta_price_lag_'+str(i)]):  # 如果不是NaN\n",
    "            return row['delta_price_lag_'+str(i)]\n",
    "    return 0\n",
    "\n",
    "matrix['delta_price_lag']=matrix.apply(select_trend, axis=1)\n",
    "matrix['delta_price_lag'] = matrix['delta_price_lag'].astype(np.float16)\n",
    "\n",
    "features_to_drop = ['item_avg_item_price','date_item_avg_item_price']\n",
    "for i in lags:\n",
    "    features_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n",
    "    features_to_drop += ['delta_price_lag_'+str(i)]\n",
    "matrix.drop(features_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# 每个月的天数\n",
    "matrix['month'] = matrix['date_block_num'] % 12\n",
    "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "matrix['days'] = matrix['month'].map(days)\n",
    "matrix['days'] = matrix['days'].astype(np.int8)\n",
    "\n",
    "# 开始销量\n",
    "matrix['item_shop_first_sale'] = matrix['date_block_num'] - matrix.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\n",
    "matrix['item_first_sale'] = matrix['date_block_num'] - matrix.groupby('item_id')['date_block_num'].transform('min')\n",
    "\n",
    "# 因为有12个月的延迟特征（1，2，3，6，12）（1，2，3，4，5，6，12），所以需要删除前12月的数据\n",
    "matrix = matrix[matrix['date_block_num'] > 11]\n",
    "\n",
    "# 找到有NaN值的列，然后把那些列中的NaN值填充0\n",
    "columns = matrix.columns\n",
    "column_null = []\n",
    "for i in columns:\n",
    "    if len(matrix[matrix[i].isnull()]) > 0:\n",
    "        column_null.append(i)\n",
    "\n",
    "for i in column_null:\n",
    "    matrix[i].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>cat_type_code</th>\n",
       "      <th>cat_subtype_code</th>\n",
       "      <th>shop_city_code</th>\n",
       "      <th>shop_type_code</th>\n",
       "      <th>item_cnt_month_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>date_item_city_avg_item_cnt_lag_1</th>\n",
       "      <th>date_item_city_avg_item_cnt_lag_2</th>\n",
       "      <th>date_item_city_avg_item_cnt_lag_3</th>\n",
       "      <th>date_item_city_avg_item_cnt_lag_6</th>\n",
       "      <th>date_item_city_avg_item_cnt_lag_12</th>\n",
       "      <th>delta_price_lag</th>\n",
       "      <th>month</th>\n",
       "      <th>days</th>\n",
       "      <th>item_shop_first_sale</th>\n",
       "      <th>item_first_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4488756</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.282715</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488757</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.483398</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488758</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.137451</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488759</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.407227</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488760</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.225464</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128045</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>18454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.475098</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128046</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>16188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081116</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128047</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>15757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155884</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128048</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>19648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.091736</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128049</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.605957</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6639294 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date_block_num  shop_id  item_id  item_cnt_month  item_category_id  \\\n",
       "4488756               12        2       27             0.0                19   \n",
       "4488757               12        2       30             0.0                40   \n",
       "4488758               12        2       31             0.0                37   \n",
       "4488759               12        2       32             1.0                40   \n",
       "4488760               12        2       33             1.0                37   \n",
       "...                  ...      ...      ...             ...               ...   \n",
       "11128045              34       45    18454             0.0                55   \n",
       "11128046              34       45    16188             0.0                64   \n",
       "11128047              34       45    15757             0.0                55   \n",
       "11128048              34       45    19648             0.0                40   \n",
       "11128049              34       45      969             0.0                37   \n",
       "\n",
       "          cat_type_code  cat_subtype_code  shop_city_code  shop_type_code  \\\n",
       "4488756               5                10               1               4   \n",
       "4488757              11                 4               1               4   \n",
       "4488758              11                 1               1               4   \n",
       "4488759              11                 4               1               4   \n",
       "4488760              11                 1               1               4   \n",
       "...                 ...               ...             ...             ...   \n",
       "11128045             13                 2              21               4   \n",
       "11128046             14                42              21               4   \n",
       "11128047             13                 2              21               4   \n",
       "11128048             11                 4              21               4   \n",
       "11128049             11                 1              21               4   \n",
       "\n",
       "          item_cnt_month_lag_1  ...  date_item_city_avg_item_cnt_lag_1  \\\n",
       "4488756                    0.0  ...                                0.0   \n",
       "4488757                    0.0  ...                                0.0   \n",
       "4488758                    0.0  ...                                0.0   \n",
       "4488759                    0.0  ...                                0.0   \n",
       "4488760                    1.0  ...                                1.0   \n",
       "...                        ...  ...                                ...   \n",
       "11128045                   1.0  ...                                0.5   \n",
       "11128046                   0.0  ...                                0.0   \n",
       "11128047                   0.0  ...                                0.0   \n",
       "11128048                   0.0  ...                                0.0   \n",
       "11128049                   0.0  ...                                0.5   \n",
       "\n",
       "          date_item_city_avg_item_cnt_lag_2  \\\n",
       "4488756                                 0.0   \n",
       "4488757                                 0.0   \n",
       "4488758                                 0.0   \n",
       "4488759                                 0.0   \n",
       "4488760                                 2.0   \n",
       "...                                     ...   \n",
       "11128045                                0.0   \n",
       "11128046                                0.0   \n",
       "11128047                                0.5   \n",
       "11128048                                0.0   \n",
       "11128049                                0.0   \n",
       "\n",
       "          date_item_city_avg_item_cnt_lag_3  \\\n",
       "4488756                                 0.0   \n",
       "4488757                                 0.0   \n",
       "4488758                                 0.0   \n",
       "4488759                                 0.0   \n",
       "4488760                                 0.0   \n",
       "...                                     ...   \n",
       "11128045                                0.0   \n",
       "11128046                                0.0   \n",
       "11128047                                0.0   \n",
       "11128048                                0.0   \n",
       "11128049                                0.0   \n",
       "\n",
       "          date_item_city_avg_item_cnt_lag_6  \\\n",
       "4488756                                 0.0   \n",
       "4488757                                 0.0   \n",
       "4488758                                 0.0   \n",
       "4488759                                 0.0   \n",
       "4488760                                 0.0   \n",
       "...                                     ...   \n",
       "11128045                                0.0   \n",
       "11128046                                0.0   \n",
       "11128047                                0.0   \n",
       "11128048                                0.0   \n",
       "11128049                                0.0   \n",
       "\n",
       "          date_item_city_avg_item_cnt_lag_12  delta_price_lag  month  days  \\\n",
       "4488756                                  1.0        -0.282715      0    31   \n",
       "4488757                                  0.0        -0.483398      0    31   \n",
       "4488758                                  0.0        -0.137451      0    31   \n",
       "4488759                                  0.0        -0.407227      0    31   \n",
       "4488760                                  1.0        -0.225464      0    31   \n",
       "...                                      ...              ...    ...   ...   \n",
       "11128045                                 0.0        -0.475098     10    30   \n",
       "11128046                                 0.0         0.081116     10    30   \n",
       "11128047                                 0.0         0.155884     10    30   \n",
       "11128048                                 0.0        -0.091736     10    30   \n",
       "11128049                                 0.0        -0.605957     10    30   \n",
       "\n",
       "          item_shop_first_sale  item_first_sale  \n",
       "4488756                     12               12  \n",
       "4488757                     11               11  \n",
       "4488758                     11               11  \n",
       "4488759                     12               12  \n",
       "4488760                     12               12  \n",
       "...                        ...              ...  \n",
       "11128045                    11               11  \n",
       "11128046                     2                2  \n",
       "11128047                    34               34  \n",
       "11128048                    11               11  \n",
       "11128049                    17               17  \n",
       "\n",
       "[6639294 rows x 64 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = matrix[matrix['date_block_num'] < 33]\n",
    "label_train = trainData['item_cnt_month']\n",
    "X_train = trainData.drop('item_cnt_month', axis=1)\n",
    "\n",
    "validData = matrix[matrix['date_block_num'] == 33]\n",
    "label_valid = validData['item_cnt_month']\n",
    "X_valid = validData.drop('item_cnt_month', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(data=X_train, label=label_train)\n",
    "valid_data = lgb.Dataset(data=X_valid, label=label_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'regression', 'metric': 'rmse', 'n_estimators': 1000, 'num_leaves': 200, 'learning_rate': 0.01, 'bagging_fraction': 0.9, 'feature_fraction': 0.3, 'bagging_seed': 0, 'early_stop_rounds': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python37\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: early_stop_rounds\n",
      "[LightGBM] [Warning] Unknown parameter: early_stop_rounds\n",
      "[LightGBM] [Warning] Unknown parameter: early_stop_rounds\n",
      "[LightGBM] [Warning] Unknown parameter: early_stop_rounds\n",
      "[LightGBM] [Warning] Unknown parameter: early_stop_rounds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.242558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10805\n",
      "[LightGBM] [Info] Number of data points in the train set: 6186922, number of used features: 63\n",
      "[LightGBM] [Info] Start training from score 0.288852\n",
      "[1]\ttraining's rmse: 1.18283\tvalid_1's rmse: 1.13262\n",
      "[2]\ttraining's rmse: 1.17757\tvalid_1's rmse: 1.12866\n",
      "[3]\ttraining's rmse: 1.17357\tvalid_1's rmse: 1.12527\n",
      "[4]\ttraining's rmse: 1.16976\tvalid_1's rmse: 1.12263\n",
      "[5]\ttraining's rmse: 1.16472\tvalid_1's rmse: 1.11879\n",
      "[6]\ttraining's rmse: 1.16109\tvalid_1's rmse: 1.11575\n",
      "[7]\ttraining's rmse: 1.1568\tvalid_1's rmse: 1.11241\n",
      "[8]\ttraining's rmse: 1.15208\tvalid_1's rmse: 1.10907\n",
      "[9]\ttraining's rmse: 1.14774\tvalid_1's rmse: 1.106\n",
      "[10]\ttraining's rmse: 1.14303\tvalid_1's rmse: 1.10249\n",
      "[11]\ttraining's rmse: 1.13831\tvalid_1's rmse: 1.09893\n",
      "[12]\ttraining's rmse: 1.13397\tvalid_1's rmse: 1.09574\n",
      "[13]\ttraining's rmse: 1.12977\tvalid_1's rmse: 1.09284\n",
      "[14]\ttraining's rmse: 1.12595\tvalid_1's rmse: 1.09026\n",
      "[15]\ttraining's rmse: 1.12215\tvalid_1's rmse: 1.08756\n",
      "[16]\ttraining's rmse: 1.11815\tvalid_1's rmse: 1.08471\n",
      "[17]\ttraining's rmse: 1.11439\tvalid_1's rmse: 1.08215\n",
      "[18]\ttraining's rmse: 1.11052\tvalid_1's rmse: 1.07958\n",
      "[19]\ttraining's rmse: 1.10645\tvalid_1's rmse: 1.07665\n",
      "[20]\ttraining's rmse: 1.10284\tvalid_1's rmse: 1.07434\n",
      "[21]\ttraining's rmse: 1.09912\tvalid_1's rmse: 1.07176\n",
      "[22]\ttraining's rmse: 1.09544\tvalid_1's rmse: 1.06903\n",
      "[23]\ttraining's rmse: 1.09195\tvalid_1's rmse: 1.06632\n",
      "[24]\ttraining's rmse: 1.08811\tvalid_1's rmse: 1.06356\n",
      "[25]\ttraining's rmse: 1.08424\tvalid_1's rmse: 1.06086\n",
      "[26]\ttraining's rmse: 1.08053\tvalid_1's rmse: 1.05831\n",
      "[27]\ttraining's rmse: 1.07743\tvalid_1's rmse: 1.05582\n",
      "[28]\ttraining's rmse: 1.07355\tvalid_1's rmse: 1.05346\n",
      "[29]\ttraining's rmse: 1.07031\tvalid_1's rmse: 1.05132\n",
      "[30]\ttraining's rmse: 1.06695\tvalid_1's rmse: 1.04905\n",
      "[31]\ttraining's rmse: 1.06341\tvalid_1's rmse: 1.04651\n",
      "[32]\ttraining's rmse: 1.06044\tvalid_1's rmse: 1.04451\n",
      "[33]\ttraining's rmse: 1.05815\tvalid_1's rmse: 1.04291\n",
      "[34]\ttraining's rmse: 1.05467\tvalid_1's rmse: 1.04052\n",
      "[35]\ttraining's rmse: 1.05166\tvalid_1's rmse: 1.0386\n",
      "[36]\ttraining's rmse: 1.04901\tvalid_1's rmse: 1.03691\n",
      "[37]\ttraining's rmse: 1.04616\tvalid_1's rmse: 1.03463\n",
      "[38]\ttraining's rmse: 1.04391\tvalid_1's rmse: 1.033\n",
      "[39]\ttraining's rmse: 1.04072\tvalid_1's rmse: 1.03138\n",
      "[40]\ttraining's rmse: 1.03774\tvalid_1's rmse: 1.02938\n",
      "[41]\ttraining's rmse: 1.03461\tvalid_1's rmse: 1.02727\n",
      "[42]\ttraining's rmse: 1.0318\tvalid_1's rmse: 1.02557\n",
      "[43]\ttraining's rmse: 1.02906\tvalid_1's rmse: 1.02387\n",
      "[44]\ttraining's rmse: 1.02645\tvalid_1's rmse: 1.02225\n",
      "[45]\ttraining's rmse: 1.02439\tvalid_1's rmse: 1.02091\n",
      "[46]\ttraining's rmse: 1.02129\tvalid_1's rmse: 1.01914\n",
      "[47]\ttraining's rmse: 1.0185\tvalid_1's rmse: 1.01731\n",
      "[48]\ttraining's rmse: 1.01538\tvalid_1's rmse: 1.01514\n",
      "[49]\ttraining's rmse: 1.01266\tvalid_1's rmse: 1.01367\n",
      "[50]\ttraining's rmse: 1.00969\tvalid_1's rmse: 1.01174\n",
      "[51]\ttraining's rmse: 1.00703\tvalid_1's rmse: 1.00986\n",
      "[52]\ttraining's rmse: 1.00441\tvalid_1's rmse: 1.00811\n",
      "[53]\ttraining's rmse: 1.00187\tvalid_1's rmse: 1.00645\n",
      "[54]\ttraining's rmse: 0.999112\tvalid_1's rmse: 1.00463\n",
      "[55]\ttraining's rmse: 0.996654\tvalid_1's rmse: 1.00285\n",
      "[56]\ttraining's rmse: 0.9945\tvalid_1's rmse: 1.00114\n",
      "[57]\ttraining's rmse: 0.991944\tvalid_1's rmse: 0.99929\n",
      "[58]\ttraining's rmse: 0.989463\tvalid_1's rmse: 0.997762\n",
      "[59]\ttraining's rmse: 0.98685\tvalid_1's rmse: 0.995952\n",
      "[60]\ttraining's rmse: 0.983858\tvalid_1's rmse: 0.994363\n",
      "[61]\ttraining's rmse: 0.981763\tvalid_1's rmse: 0.993019\n",
      "[62]\ttraining's rmse: 0.979661\tvalid_1's rmse: 0.991791\n",
      "[63]\ttraining's rmse: 0.977372\tvalid_1's rmse: 0.990331\n",
      "[64]\ttraining's rmse: 0.975601\tvalid_1's rmse: 0.989204\n",
      "[65]\ttraining's rmse: 0.973665\tvalid_1's rmse: 0.987915\n",
      "[66]\ttraining's rmse: 0.971633\tvalid_1's rmse: 0.986683\n",
      "[67]\ttraining's rmse: 0.969556\tvalid_1's rmse: 0.985328\n",
      "[68]\ttraining's rmse: 0.968053\tvalid_1's rmse: 0.984335\n",
      "[69]\ttraining's rmse: 0.965594\tvalid_1's rmse: 0.982524\n",
      "[70]\ttraining's rmse: 0.963425\tvalid_1's rmse: 0.981284\n",
      "[71]\ttraining's rmse: 0.961239\tvalid_1's rmse: 0.979879\n",
      "[72]\ttraining's rmse: 0.958967\tvalid_1's rmse: 0.978445\n",
      "[73]\ttraining's rmse: 0.957041\tvalid_1's rmse: 0.977222\n",
      "[74]\ttraining's rmse: 0.955117\tvalid_1's rmse: 0.97596\n",
      "[75]\ttraining's rmse: 0.952966\tvalid_1's rmse: 0.974546\n",
      "[76]\ttraining's rmse: 0.951122\tvalid_1's rmse: 0.973301\n",
      "[77]\ttraining's rmse: 0.949012\tvalid_1's rmse: 0.971957\n",
      "[78]\ttraining's rmse: 0.947022\tvalid_1's rmse: 0.970759\n",
      "[79]\ttraining's rmse: 0.945335\tvalid_1's rmse: 0.969508\n",
      "[80]\ttraining's rmse: 0.94402\tvalid_1's rmse: 0.968686\n",
      "[81]\ttraining's rmse: 0.942186\tvalid_1's rmse: 0.96774\n",
      "[82]\ttraining's rmse: 0.940549\tvalid_1's rmse: 0.966751\n",
      "[83]\ttraining's rmse: 0.938794\tvalid_1's rmse: 0.965741\n",
      "[84]\ttraining's rmse: 0.937313\tvalid_1's rmse: 0.964758\n",
      "[85]\ttraining's rmse: 0.935633\tvalid_1's rmse: 0.963674\n",
      "[86]\ttraining's rmse: 0.933892\tvalid_1's rmse: 0.962599\n",
      "[87]\ttraining's rmse: 0.932764\tvalid_1's rmse: 0.961927\n",
      "[88]\ttraining's rmse: 0.930892\tvalid_1's rmse: 0.960668\n",
      "[89]\ttraining's rmse: 0.92915\tvalid_1's rmse: 0.959677\n",
      "[90]\ttraining's rmse: 0.927411\tvalid_1's rmse: 0.959038\n",
      "[91]\ttraining's rmse: 0.925768\tvalid_1's rmse: 0.958061\n",
      "[92]\ttraining's rmse: 0.924183\tvalid_1's rmse: 0.957144\n",
      "[93]\ttraining's rmse: 0.922599\tvalid_1's rmse: 0.956222\n",
      "[94]\ttraining's rmse: 0.921272\tvalid_1's rmse: 0.95548\n",
      "[95]\ttraining's rmse: 0.919624\tvalid_1's rmse: 0.954476\n",
      "[96]\ttraining's rmse: 0.917982\tvalid_1's rmse: 0.953458\n",
      "[97]\ttraining's rmse: 0.916729\tvalid_1's rmse: 0.952769\n",
      "[98]\ttraining's rmse: 0.915069\tvalid_1's rmse: 0.951887\n",
      "[99]\ttraining's rmse: 0.914128\tvalid_1's rmse: 0.951341\n",
      "[100]\ttraining's rmse: 0.912778\tvalid_1's rmse: 0.950544\n",
      "[101]\ttraining's rmse: 0.911434\tvalid_1's rmse: 0.94977\n",
      "[102]\ttraining's rmse: 0.909917\tvalid_1's rmse: 0.948893\n",
      "[103]\ttraining's rmse: 0.908687\tvalid_1's rmse: 0.948251\n",
      "[104]\ttraining's rmse: 0.906935\tvalid_1's rmse: 0.947604\n",
      "[105]\ttraining's rmse: 0.905194\tvalid_1's rmse: 0.947213\n",
      "[106]\ttraining's rmse: 0.903624\tvalid_1's rmse: 0.946277\n",
      "[107]\ttraining's rmse: 0.902484\tvalid_1's rmse: 0.945689\n",
      "[108]\ttraining's rmse: 0.900917\tvalid_1's rmse: 0.945448\n",
      "[109]\ttraining's rmse: 0.900033\tvalid_1's rmse: 0.944937\n",
      "[110]\ttraining's rmse: 0.898744\tvalid_1's rmse: 0.944196\n",
      "[111]\ttraining's rmse: 0.897613\tvalid_1's rmse: 0.943526\n",
      "[112]\ttraining's rmse: 0.896274\tvalid_1's rmse: 0.942815\n",
      "[113]\ttraining's rmse: 0.895106\tvalid_1's rmse: 0.942251\n",
      "[114]\ttraining's rmse: 0.894201\tvalid_1's rmse: 0.941583\n",
      "[115]\ttraining's rmse: 0.892956\tvalid_1's rmse: 0.940837\n",
      "[116]\ttraining's rmse: 0.8917\tvalid_1's rmse: 0.940155\n",
      "[117]\ttraining's rmse: 0.890682\tvalid_1's rmse: 0.939652\n",
      "[118]\ttraining's rmse: 0.889066\tvalid_1's rmse: 0.939332\n",
      "[119]\ttraining's rmse: 0.888137\tvalid_1's rmse: 0.938694\n",
      "[120]\ttraining's rmse: 0.887111\tvalid_1's rmse: 0.938253\n",
      "[121]\ttraining's rmse: 0.886155\tvalid_1's rmse: 0.937675\n",
      "[122]\ttraining's rmse: 0.885007\tvalid_1's rmse: 0.937096\n",
      "[123]\ttraining's rmse: 0.883986\tvalid_1's rmse: 0.93649\n",
      "[124]\ttraining's rmse: 0.88298\tvalid_1's rmse: 0.935979\n",
      "[125]\ttraining's rmse: 0.882003\tvalid_1's rmse: 0.935502\n",
      "[126]\ttraining's rmse: 0.880898\tvalid_1's rmse: 0.935039\n",
      "[127]\ttraining's rmse: 0.87981\tvalid_1's rmse: 0.934592\n",
      "[128]\ttraining's rmse: 0.87856\tvalid_1's rmse: 0.93431\n",
      "[129]\ttraining's rmse: 0.877661\tvalid_1's rmse: 0.933735\n",
      "[130]\ttraining's rmse: 0.876689\tvalid_1's rmse: 0.933459\n",
      "[131]\ttraining's rmse: 0.87552\tvalid_1's rmse: 0.932867\n",
      "[132]\ttraining's rmse: 0.874574\tvalid_1's rmse: 0.932491\n",
      "[133]\ttraining's rmse: 0.87365\tvalid_1's rmse: 0.932029\n",
      "[134]\ttraining's rmse: 0.872628\tvalid_1's rmse: 0.931519\n",
      "[135]\ttraining's rmse: 0.871706\tvalid_1's rmse: 0.931045\n",
      "[136]\ttraining's rmse: 0.870804\tvalid_1's rmse: 0.930502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137]\ttraining's rmse: 0.869926\tvalid_1's rmse: 0.930106\n",
      "[138]\ttraining's rmse: 0.868991\tvalid_1's rmse: 0.929619\n",
      "[139]\ttraining's rmse: 0.868175\tvalid_1's rmse: 0.92922\n",
      "[140]\ttraining's rmse: 0.867385\tvalid_1's rmse: 0.928868\n",
      "[141]\ttraining's rmse: 0.866558\tvalid_1's rmse: 0.928469\n",
      "[142]\ttraining's rmse: 0.865868\tvalid_1's rmse: 0.928056\n",
      "[143]\ttraining's rmse: 0.864782\tvalid_1's rmse: 0.927573\n",
      "[144]\ttraining's rmse: 0.864002\tvalid_1's rmse: 0.927312\n",
      "[145]\ttraining's rmse: 0.863154\tvalid_1's rmse: 0.926869\n",
      "[146]\ttraining's rmse: 0.862393\tvalid_1's rmse: 0.926482\n",
      "[147]\ttraining's rmse: 0.861693\tvalid_1's rmse: 0.926136\n",
      "[148]\ttraining's rmse: 0.861001\tvalid_1's rmse: 0.925949\n",
      "[149]\ttraining's rmse: 0.860197\tvalid_1's rmse: 0.925776\n",
      "[150]\ttraining's rmse: 0.859419\tvalid_1's rmse: 0.925452\n",
      "[151]\ttraining's rmse: 0.858858\tvalid_1's rmse: 0.925169\n",
      "[152]\ttraining's rmse: 0.858105\tvalid_1's rmse: 0.924538\n",
      "[153]\ttraining's rmse: 0.857447\tvalid_1's rmse: 0.924264\n",
      "[154]\ttraining's rmse: 0.85703\tvalid_1's rmse: 0.924093\n",
      "[155]\ttraining's rmse: 0.856271\tvalid_1's rmse: 0.923727\n",
      "[156]\ttraining's rmse: 0.855606\tvalid_1's rmse: 0.923479\n",
      "[157]\ttraining's rmse: 0.855112\tvalid_1's rmse: 0.923169\n",
      "[158]\ttraining's rmse: 0.854425\tvalid_1's rmse: 0.923073\n",
      "[159]\ttraining's rmse: 0.853783\tvalid_1's rmse: 0.922831\n",
      "[160]\ttraining's rmse: 0.853002\tvalid_1's rmse: 0.922491\n",
      "[161]\ttraining's rmse: 0.852345\tvalid_1's rmse: 0.9223\n",
      "[162]\ttraining's rmse: 0.851301\tvalid_1's rmse: 0.922318\n",
      "[163]\ttraining's rmse: 0.850469\tvalid_1's rmse: 0.922127\n",
      "[164]\ttraining's rmse: 0.849676\tvalid_1's rmse: 0.922074\n",
      "[165]\ttraining's rmse: 0.848919\tvalid_1's rmse: 0.921903\n",
      "[166]\ttraining's rmse: 0.84825\tvalid_1's rmse: 0.921706\n",
      "[167]\ttraining's rmse: 0.847618\tvalid_1's rmse: 0.921502\n",
      "[168]\ttraining's rmse: 0.84699\tvalid_1's rmse: 0.921241\n",
      "[169]\ttraining's rmse: 0.846357\tvalid_1's rmse: 0.921066\n",
      "[170]\ttraining's rmse: 0.845763\tvalid_1's rmse: 0.920798\n",
      "[171]\ttraining's rmse: 0.845035\tvalid_1's rmse: 0.920271\n",
      "[172]\ttraining's rmse: 0.844348\tvalid_1's rmse: 0.919836\n",
      "[173]\ttraining's rmse: 0.844009\tvalid_1's rmse: 0.919627\n",
      "[174]\ttraining's rmse: 0.843491\tvalid_1's rmse: 0.919449\n",
      "[175]\ttraining's rmse: 0.842954\tvalid_1's rmse: 0.919286\n",
      "[176]\ttraining's rmse: 0.842296\tvalid_1's rmse: 0.919078\n",
      "[177]\ttraining's rmse: 0.841703\tvalid_1's rmse: 0.919229\n",
      "[178]\ttraining's rmse: 0.841216\tvalid_1's rmse: 0.919059\n",
      "[179]\ttraining's rmse: 0.840708\tvalid_1's rmse: 0.918861\n",
      "[180]\ttraining's rmse: 0.840253\tvalid_1's rmse: 0.918674\n",
      "[181]\ttraining's rmse: 0.839561\tvalid_1's rmse: 0.918495\n",
      "[182]\ttraining's rmse: 0.839119\tvalid_1's rmse: 0.918296\n",
      "[183]\ttraining's rmse: 0.838596\tvalid_1's rmse: 0.918145\n",
      "[184]\ttraining's rmse: 0.83807\tvalid_1's rmse: 0.917967\n",
      "[185]\ttraining's rmse: 0.837616\tvalid_1's rmse: 0.917805\n",
      "[186]\ttraining's rmse: 0.837128\tvalid_1's rmse: 0.917664\n",
      "[187]\ttraining's rmse: 0.836199\tvalid_1's rmse: 0.917993\n",
      "[188]\ttraining's rmse: 0.835658\tvalid_1's rmse: 0.917774\n",
      "[189]\ttraining's rmse: 0.835041\tvalid_1's rmse: 0.917552\n",
      "[190]\ttraining's rmse: 0.834594\tvalid_1's rmse: 0.917396\n",
      "[191]\ttraining's rmse: 0.834126\tvalid_1's rmse: 0.917237\n",
      "[192]\ttraining's rmse: 0.833679\tvalid_1's rmse: 0.917074\n",
      "[193]\ttraining's rmse: 0.833192\tvalid_1's rmse: 0.91689\n",
      "[194]\ttraining's rmse: 0.832663\tvalid_1's rmse: 0.916669\n",
      "[195]\ttraining's rmse: 0.832211\tvalid_1's rmse: 0.916577\n",
      "[196]\ttraining's rmse: 0.831724\tvalid_1's rmse: 0.916374\n",
      "[197]\ttraining's rmse: 0.831228\tvalid_1's rmse: 0.91634\n",
      "[198]\ttraining's rmse: 0.830843\tvalid_1's rmse: 0.916247\n",
      "[199]\ttraining's rmse: 0.830545\tvalid_1's rmse: 0.916104\n",
      "[200]\ttraining's rmse: 0.830061\tvalid_1's rmse: 0.915901\n",
      "[201]\ttraining's rmse: 0.829516\tvalid_1's rmse: 0.915702\n",
      "[202]\ttraining's rmse: 0.829055\tvalid_1's rmse: 0.915568\n",
      "[203]\ttraining's rmse: 0.828722\tvalid_1's rmse: 0.91524\n",
      "[204]\ttraining's rmse: 0.827838\tvalid_1's rmse: 0.915373\n",
      "[205]\ttraining's rmse: 0.827337\tvalid_1's rmse: 0.915313\n",
      "[206]\ttraining's rmse: 0.826838\tvalid_1's rmse: 0.915243\n",
      "[207]\ttraining's rmse: 0.826367\tvalid_1's rmse: 0.91502\n",
      "[208]\ttraining's rmse: 0.825921\tvalid_1's rmse: 0.91496\n",
      "[209]\ttraining's rmse: 0.82542\tvalid_1's rmse: 0.914795\n",
      "[210]\ttraining's rmse: 0.82498\tvalid_1's rmse: 0.914698\n",
      "[211]\ttraining's rmse: 0.824552\tvalid_1's rmse: 0.914666\n",
      "[212]\ttraining's rmse: 0.824149\tvalid_1's rmse: 0.914495\n",
      "[213]\ttraining's rmse: 0.823418\tvalid_1's rmse: 0.914942\n",
      "[214]\ttraining's rmse: 0.823091\tvalid_1's rmse: 0.914968\n",
      "[215]\ttraining's rmse: 0.822693\tvalid_1's rmse: 0.914855\n",
      "[216]\ttraining's rmse: 0.822396\tvalid_1's rmse: 0.914796\n",
      "[217]\ttraining's rmse: 0.821738\tvalid_1's rmse: 0.914806\n",
      "[218]\ttraining's rmse: 0.821431\tvalid_1's rmse: 0.914749\n",
      "[219]\ttraining's rmse: 0.821017\tvalid_1's rmse: 0.914641\n",
      "[220]\ttraining's rmse: 0.820631\tvalid_1's rmse: 0.914482\n",
      "[221]\ttraining's rmse: 0.820325\tvalid_1's rmse: 0.914378\n",
      "[222]\ttraining's rmse: 0.819948\tvalid_1's rmse: 0.914291\n",
      "[223]\ttraining's rmse: 0.819625\tvalid_1's rmse: 0.91428\n",
      "[224]\ttraining's rmse: 0.819308\tvalid_1's rmse: 0.914229\n",
      "[225]\ttraining's rmse: 0.818975\tvalid_1's rmse: 0.914133\n",
      "[226]\ttraining's rmse: 0.818658\tvalid_1's rmse: 0.914096\n",
      "[227]\ttraining's rmse: 0.818145\tvalid_1's rmse: 0.914192\n",
      "[228]\ttraining's rmse: 0.817767\tvalid_1's rmse: 0.914113\n",
      "[229]\ttraining's rmse: 0.817527\tvalid_1's rmse: 0.914087\n",
      "[230]\ttraining's rmse: 0.817174\tvalid_1's rmse: 0.914019\n",
      "[231]\ttraining's rmse: 0.816775\tvalid_1's rmse: 0.913935\n",
      "[232]\ttraining's rmse: 0.816453\tvalid_1's rmse: 0.91387\n",
      "[233]\ttraining's rmse: 0.816069\tvalid_1's rmse: 0.913798\n",
      "[234]\ttraining's rmse: 0.815672\tvalid_1's rmse: 0.913729\n",
      "[235]\ttraining's rmse: 0.815095\tvalid_1's rmse: 0.914339\n",
      "[236]\ttraining's rmse: 0.81477\tvalid_1's rmse: 0.914353\n",
      "[237]\ttraining's rmse: 0.814435\tvalid_1's rmse: 0.914326\n",
      "[238]\ttraining's rmse: 0.814092\tvalid_1's rmse: 0.914279\n",
      "[239]\ttraining's rmse: 0.81379\tvalid_1's rmse: 0.914283\n",
      "[240]\ttraining's rmse: 0.813509\tvalid_1's rmse: 0.914232\n",
      "[241]\ttraining's rmse: 0.812969\tvalid_1's rmse: 0.914416\n",
      "[242]\ttraining's rmse: 0.812542\tvalid_1's rmse: 0.91459\n",
      "[243]\ttraining's rmse: 0.812208\tvalid_1's rmse: 0.91452\n",
      "[244]\ttraining's rmse: 0.811527\tvalid_1's rmse: 0.914725\n",
      "[245]\ttraining's rmse: 0.811\tvalid_1's rmse: 0.914907\n",
      "[246]\ttraining's rmse: 0.810727\tvalid_1's rmse: 0.914878\n",
      "[247]\ttraining's rmse: 0.810444\tvalid_1's rmse: 0.914792\n",
      "[248]\ttraining's rmse: 0.810116\tvalid_1's rmse: 0.91472\n",
      "[249]\ttraining's rmse: 0.809875\tvalid_1's rmse: 0.914667\n",
      "[250]\ttraining's rmse: 0.809515\tvalid_1's rmse: 0.914592\n",
      "[251]\ttraining's rmse: 0.809256\tvalid_1's rmse: 0.914583\n",
      "[252]\ttraining's rmse: 0.808962\tvalid_1's rmse: 0.91456\n",
      "[253]\ttraining's rmse: 0.808686\tvalid_1's rmse: 0.914572\n",
      "[254]\ttraining's rmse: 0.808386\tvalid_1's rmse: 0.914553\n",
      "[255]\ttraining's rmse: 0.807878\tvalid_1's rmse: 0.914608\n",
      "[256]\ttraining's rmse: 0.807465\tvalid_1's rmse: 0.914886\n",
      "[257]\ttraining's rmse: 0.807196\tvalid_1's rmse: 0.914872\n",
      "[258]\ttraining's rmse: 0.806959\tvalid_1's rmse: 0.914786\n",
      "[259]\ttraining's rmse: 0.806692\tvalid_1's rmse: 0.914823\n",
      "[260]\ttraining's rmse: 0.806374\tvalid_1's rmse: 0.914631\n",
      "[261]\ttraining's rmse: 0.80617\tvalid_1's rmse: 0.914582\n",
      "[262]\ttraining's rmse: 0.805707\tvalid_1's rmse: 0.914683\n",
      "[263]\ttraining's rmse: 0.805424\tvalid_1's rmse: 0.914648\n",
      "[264]\ttraining's rmse: 0.805146\tvalid_1's rmse: 0.914593\n",
      "[265]\ttraining's rmse: 0.804893\tvalid_1's rmse: 0.91449\n",
      "[266]\ttraining's rmse: 0.804451\tvalid_1's rmse: 0.914563\n",
      "[267]\ttraining's rmse: 0.804243\tvalid_1's rmse: 0.914536\n",
      "[268]\ttraining's rmse: 0.803855\tvalid_1's rmse: 0.914533\n",
      "[269]\ttraining's rmse: 0.803522\tvalid_1's rmse: 0.914408\n",
      "[270]\ttraining's rmse: 0.803303\tvalid_1's rmse: 0.914368\n",
      "[271]\ttraining's rmse: 0.80302\tvalid_1's rmse: 0.914407\n",
      "[272]\ttraining's rmse: 0.802663\tvalid_1's rmse: 0.914246\n",
      "[273]\ttraining's rmse: 0.802292\tvalid_1's rmse: 0.914241\n",
      "[274]\ttraining's rmse: 0.802026\tvalid_1's rmse: 0.914117\n",
      "[275]\ttraining's rmse: 0.801809\tvalid_1's rmse: 0.914045\n",
      "[276]\ttraining's rmse: 0.801591\tvalid_1's rmse: 0.914031\n",
      "[277]\ttraining's rmse: 0.801316\tvalid_1's rmse: 0.914044\n",
      "[278]\ttraining's rmse: 0.800978\tvalid_1's rmse: 0.913867\n",
      "[279]\ttraining's rmse: 0.800768\tvalid_1's rmse: 0.913806\n",
      "[280]\ttraining's rmse: 0.800577\tvalid_1's rmse: 0.913786\n",
      "[281]\ttraining's rmse: 0.800371\tvalid_1's rmse: 0.91376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[282]\ttraining's rmse: 0.800164\tvalid_1's rmse: 0.913745\n",
      "[283]\ttraining's rmse: 0.799961\tvalid_1's rmse: 0.913771\n",
      "[284]\ttraining's rmse: 0.799777\tvalid_1's rmse: 0.913692\n",
      "[285]\ttraining's rmse: 0.799596\tvalid_1's rmse: 0.913694\n",
      "[286]\ttraining's rmse: 0.799225\tvalid_1's rmse: 0.913634\n",
      "[287]\ttraining's rmse: 0.798972\tvalid_1's rmse: 0.913623\n",
      "[288]\ttraining's rmse: 0.798616\tvalid_1's rmse: 0.913952\n",
      "[289]\ttraining's rmse: 0.798372\tvalid_1's rmse: 0.913834\n",
      "[290]\ttraining's rmse: 0.798149\tvalid_1's rmse: 0.913845\n",
      "[291]\ttraining's rmse: 0.797971\tvalid_1's rmse: 0.913792\n",
      "[292]\ttraining's rmse: 0.797779\tvalid_1's rmse: 0.913834\n",
      "[293]\ttraining's rmse: 0.797477\tvalid_1's rmse: 0.913785\n",
      "[294]\ttraining's rmse: 0.7972\tvalid_1's rmse: 0.913738\n",
      "[295]\ttraining's rmse: 0.797039\tvalid_1's rmse: 0.913739\n",
      "[296]\ttraining's rmse: 0.796679\tvalid_1's rmse: 0.913726\n",
      "[297]\ttraining's rmse: 0.796514\tvalid_1's rmse: 0.913664\n",
      "[298]\ttraining's rmse: 0.796227\tvalid_1's rmse: 0.913631\n",
      "[299]\ttraining's rmse: 0.79591\tvalid_1's rmse: 0.913819\n",
      "[300]\ttraining's rmse: 0.795578\tvalid_1's rmse: 0.913702\n",
      "[301]\ttraining's rmse: 0.795278\tvalid_1's rmse: 0.913563\n",
      "[302]\ttraining's rmse: 0.794999\tvalid_1's rmse: 0.913538\n",
      "[303]\ttraining's rmse: 0.794801\tvalid_1's rmse: 0.913522\n",
      "[304]\ttraining's rmse: 0.794581\tvalid_1's rmse: 0.913522\n",
      "[305]\ttraining's rmse: 0.794377\tvalid_1's rmse: 0.913528\n",
      "[306]\ttraining's rmse: 0.794104\tvalid_1's rmse: 0.913315\n",
      "[307]\ttraining's rmse: 0.793827\tvalid_1's rmse: 0.913345\n",
      "[308]\ttraining's rmse: 0.793622\tvalid_1's rmse: 0.913306\n",
      "[309]\ttraining's rmse: 0.793439\tvalid_1's rmse: 0.913432\n",
      "[310]\ttraining's rmse: 0.793245\tvalid_1's rmse: 0.913397\n",
      "[311]\ttraining's rmse: 0.793032\tvalid_1's rmse: 0.913455\n",
      "[312]\ttraining's rmse: 0.792865\tvalid_1's rmse: 0.913409\n",
      "[313]\ttraining's rmse: 0.792336\tvalid_1's rmse: 0.91352\n",
      "[314]\ttraining's rmse: 0.792181\tvalid_1's rmse: 0.913515\n",
      "[315]\ttraining's rmse: 0.791986\tvalid_1's rmse: 0.913487\n",
      "[316]\ttraining's rmse: 0.791763\tvalid_1's rmse: 0.913383\n",
      "[317]\ttraining's rmse: 0.791571\tvalid_1's rmse: 0.913305\n",
      "[318]\ttraining's rmse: 0.791406\tvalid_1's rmse: 0.913306\n",
      "[319]\ttraining's rmse: 0.791195\tvalid_1's rmse: 0.913294\n",
      "[320]\ttraining's rmse: 0.79103\tvalid_1's rmse: 0.913231\n",
      "[321]\ttraining's rmse: 0.79081\tvalid_1's rmse: 0.91316\n",
      "[322]\ttraining's rmse: 0.790642\tvalid_1's rmse: 0.913134\n",
      "[323]\ttraining's rmse: 0.790519\tvalid_1's rmse: 0.913115\n",
      "[324]\ttraining's rmse: 0.790362\tvalid_1's rmse: 0.913064\n",
      "[325]\ttraining's rmse: 0.79022\tvalid_1's rmse: 0.913048\n",
      "[326]\ttraining's rmse: 0.790098\tvalid_1's rmse: 0.913008\n",
      "[327]\ttraining's rmse: 0.789969\tvalid_1's rmse: 0.913017\n",
      "[328]\ttraining's rmse: 0.789801\tvalid_1's rmse: 0.913002\n",
      "[329]\ttraining's rmse: 0.789543\tvalid_1's rmse: 0.913038\n",
      "[330]\ttraining's rmse: 0.789194\tvalid_1's rmse: 0.913583\n",
      "[331]\ttraining's rmse: 0.78901\tvalid_1's rmse: 0.913594\n",
      "[332]\ttraining's rmse: 0.788728\tvalid_1's rmse: 0.913822\n",
      "[333]\ttraining's rmse: 0.788496\tvalid_1's rmse: 0.913818\n",
      "[334]\ttraining's rmse: 0.788247\tvalid_1's rmse: 0.913608\n",
      "[335]\ttraining's rmse: 0.788103\tvalid_1's rmse: 0.913606\n",
      "[336]\ttraining's rmse: 0.787931\tvalid_1's rmse: 0.913568\n",
      "[337]\ttraining's rmse: 0.787766\tvalid_1's rmse: 0.913593\n",
      "[338]\ttraining's rmse: 0.787637\tvalid_1's rmse: 0.913666\n",
      "[339]\ttraining's rmse: 0.787444\tvalid_1's rmse: 0.913683\n",
      "[340]\ttraining's rmse: 0.787294\tvalid_1's rmse: 0.913719\n",
      "[341]\ttraining's rmse: 0.787127\tvalid_1's rmse: 0.913681\n",
      "[342]\ttraining's rmse: 0.786894\tvalid_1's rmse: 0.913748\n",
      "[343]\ttraining's rmse: 0.786744\tvalid_1's rmse: 0.91369\n",
      "[344]\ttraining's rmse: 0.786566\tvalid_1's rmse: 0.913754\n",
      "[345]\ttraining's rmse: 0.786433\tvalid_1's rmse: 0.913776\n",
      "[346]\ttraining's rmse: 0.786304\tvalid_1's rmse: 0.913774\n",
      "[347]\ttraining's rmse: 0.786117\tvalid_1's rmse: 0.913769\n",
      "[348]\ttraining's rmse: 0.786001\tvalid_1's rmse: 0.913785\n",
      "[349]\ttraining's rmse: 0.785848\tvalid_1's rmse: 0.913762\n",
      "[350]\ttraining's rmse: 0.785675\tvalid_1's rmse: 0.913715\n",
      "[351]\ttraining's rmse: 0.785526\tvalid_1's rmse: 0.913721\n",
      "[352]\ttraining's rmse: 0.785308\tvalid_1's rmse: 0.913642\n",
      "[353]\ttraining's rmse: 0.785181\tvalid_1's rmse: 0.913628\n",
      "[354]\ttraining's rmse: 0.784987\tvalid_1's rmse: 0.913543\n",
      "[355]\ttraining's rmse: 0.784804\tvalid_1's rmse: 0.913611\n",
      "[356]\ttraining's rmse: 0.78467\tvalid_1's rmse: 0.913626\n",
      "[357]\ttraining's rmse: 0.784531\tvalid_1's rmse: 0.913589\n",
      "[358]\ttraining's rmse: 0.784389\tvalid_1's rmse: 0.913573\n",
      "[359]\ttraining's rmse: 0.784052\tvalid_1's rmse: 0.913814\n",
      "[360]\ttraining's rmse: 0.783809\tvalid_1's rmse: 0.913808\n",
      "[361]\ttraining's rmse: 0.783416\tvalid_1's rmse: 0.914148\n",
      "[362]\ttraining's rmse: 0.783275\tvalid_1's rmse: 0.914132\n",
      "[363]\ttraining's rmse: 0.783104\tvalid_1's rmse: 0.91417\n",
      "[364]\ttraining's rmse: 0.782959\tvalid_1's rmse: 0.91421\n",
      "[365]\ttraining's rmse: 0.782745\tvalid_1's rmse: 0.914177\n",
      "[366]\ttraining's rmse: 0.782586\tvalid_1's rmse: 0.913948\n",
      "[367]\ttraining's rmse: 0.782398\tvalid_1's rmse: 0.914012\n",
      "[368]\ttraining's rmse: 0.782096\tvalid_1's rmse: 0.913999\n",
      "[369]\ttraining's rmse: 0.78196\tvalid_1's rmse: 0.914011\n",
      "[370]\ttraining's rmse: 0.781717\tvalid_1's rmse: 0.913983\n",
      "[371]\ttraining's rmse: 0.781523\tvalid_1's rmse: 0.913956\n",
      "[372]\ttraining's rmse: 0.781438\tvalid_1's rmse: 0.913986\n",
      "[373]\ttraining's rmse: 0.781257\tvalid_1's rmse: 0.91385\n",
      "[374]\ttraining's rmse: 0.781104\tvalid_1's rmse: 0.913865\n",
      "[375]\ttraining's rmse: 0.780684\tvalid_1's rmse: 0.914013\n",
      "[376]\ttraining's rmse: 0.780517\tvalid_1's rmse: 0.914019\n",
      "[377]\ttraining's rmse: 0.780332\tvalid_1's rmse: 0.913899\n",
      "[378]\ttraining's rmse: 0.780155\tvalid_1's rmse: 0.913938\n",
      "[379]\ttraining's rmse: 0.780048\tvalid_1's rmse: 0.913901\n",
      "[380]\ttraining's rmse: 0.779913\tvalid_1's rmse: 0.91392\n",
      "[381]\ttraining's rmse: 0.779711\tvalid_1's rmse: 0.91389\n",
      "[382]\ttraining's rmse: 0.779478\tvalid_1's rmse: 0.913796\n",
      "[383]\ttraining's rmse: 0.779346\tvalid_1's rmse: 0.913798\n",
      "[384]\ttraining's rmse: 0.779167\tvalid_1's rmse: 0.913789\n",
      "[385]\ttraining's rmse: 0.779017\tvalid_1's rmse: 0.913818\n",
      "[386]\ttraining's rmse: 0.778904\tvalid_1's rmse: 0.913818\n",
      "[387]\ttraining's rmse: 0.778711\tvalid_1's rmse: 0.913703\n",
      "[388]\ttraining's rmse: 0.778619\tvalid_1's rmse: 0.913676\n",
      "[389]\ttraining's rmse: 0.778467\tvalid_1's rmse: 0.913625\n",
      "[390]\ttraining's rmse: 0.778334\tvalid_1's rmse: 0.913598\n",
      "[391]\ttraining's rmse: 0.778195\tvalid_1's rmse: 0.913659\n",
      "[392]\ttraining's rmse: 0.778023\tvalid_1's rmse: 0.913594\n",
      "[393]\ttraining's rmse: 0.777899\tvalid_1's rmse: 0.913625\n",
      "[394]\ttraining's rmse: 0.777708\tvalid_1's rmse: 0.91361\n",
      "[395]\ttraining's rmse: 0.777521\tvalid_1's rmse: 0.913565\n",
      "[396]\ttraining's rmse: 0.777351\tvalid_1's rmse: 0.913554\n",
      "[397]\ttraining's rmse: 0.777195\tvalid_1's rmse: 0.913641\n",
      "[398]\ttraining's rmse: 0.777095\tvalid_1's rmse: 0.913633\n",
      "[399]\ttraining's rmse: 0.776953\tvalid_1's rmse: 0.913624\n",
      "[400]\ttraining's rmse: 0.776799\tvalid_1's rmse: 0.913583\n",
      "[401]\ttraining's rmse: 0.776595\tvalid_1's rmse: 0.913587\n",
      "[402]\ttraining's rmse: 0.776471\tvalid_1's rmse: 0.913536\n",
      "[403]\ttraining's rmse: 0.776367\tvalid_1's rmse: 0.91355\n",
      "[404]\ttraining's rmse: 0.776246\tvalid_1's rmse: 0.913525\n",
      "[405]\ttraining's rmse: 0.776128\tvalid_1's rmse: 0.913551\n",
      "[406]\ttraining's rmse: 0.775983\tvalid_1's rmse: 0.913553\n",
      "[407]\ttraining's rmse: 0.775777\tvalid_1's rmse: 0.913453\n",
      "[408]\ttraining's rmse: 0.775627\tvalid_1's rmse: 0.913457\n",
      "[409]\ttraining's rmse: 0.775497\tvalid_1's rmse: 0.913509\n",
      "[410]\ttraining's rmse: 0.775358\tvalid_1's rmse: 0.913532\n",
      "[411]\ttraining's rmse: 0.775088\tvalid_1's rmse: 0.913722\n",
      "[412]\ttraining's rmse: 0.774985\tvalid_1's rmse: 0.913681\n",
      "[413]\ttraining's rmse: 0.774806\tvalid_1's rmse: 0.91362\n",
      "[414]\ttraining's rmse: 0.774664\tvalid_1's rmse: 0.913581\n",
      "[415]\ttraining's rmse: 0.774579\tvalid_1's rmse: 0.913568\n",
      "[416]\ttraining's rmse: 0.774436\tvalid_1's rmse: 0.913533\n",
      "[417]\ttraining's rmse: 0.774237\tvalid_1's rmse: 0.91357\n",
      "[418]\ttraining's rmse: 0.774076\tvalid_1's rmse: 0.913582\n",
      "[419]\ttraining's rmse: 0.773861\tvalid_1's rmse: 0.913442\n",
      "[420]\ttraining's rmse: 0.773687\tvalid_1's rmse: 0.913413\n",
      "[421]\ttraining's rmse: 0.77356\tvalid_1's rmse: 0.913379\n",
      "[422]\ttraining's rmse: 0.773423\tvalid_1's rmse: 0.913383\n",
      "[423]\ttraining's rmse: 0.773329\tvalid_1's rmse: 0.913397\n",
      "[424]\ttraining's rmse: 0.773192\tvalid_1's rmse: 0.913407\n",
      "[425]\ttraining's rmse: 0.773096\tvalid_1's rmse: 0.913389\n",
      "[426]\ttraining's rmse: 0.772945\tvalid_1's rmse: 0.913428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[427]\ttraining's rmse: 0.772765\tvalid_1's rmse: 0.913446\n",
      "[428]\ttraining's rmse: 0.772597\tvalid_1's rmse: 0.913429\n",
      "[429]\ttraining's rmse: 0.772422\tvalid_1's rmse: 0.913363\n",
      "[430]\ttraining's rmse: 0.772223\tvalid_1's rmse: 0.913309\n",
      "[431]\ttraining's rmse: 0.772127\tvalid_1's rmse: 0.913303\n",
      "[432]\ttraining's rmse: 0.771971\tvalid_1's rmse: 0.913332\n",
      "[433]\ttraining's rmse: 0.771771\tvalid_1's rmse: 0.913323\n",
      "[434]\ttraining's rmse: 0.771607\tvalid_1's rmse: 0.913264\n",
      "[435]\ttraining's rmse: 0.771494\tvalid_1's rmse: 0.913258\n",
      "[436]\ttraining's rmse: 0.77139\tvalid_1's rmse: 0.913253\n",
      "[437]\ttraining's rmse: 0.771278\tvalid_1's rmse: 0.91326\n",
      "[438]\ttraining's rmse: 0.771059\tvalid_1's rmse: 0.913261\n",
      "[439]\ttraining's rmse: 0.770948\tvalid_1's rmse: 0.913246\n",
      "[440]\ttraining's rmse: 0.77085\tvalid_1's rmse: 0.913293\n",
      "[441]\ttraining's rmse: 0.770739\tvalid_1's rmse: 0.913258\n",
      "[442]\ttraining's rmse: 0.770599\tvalid_1's rmse: 0.913298\n",
      "[443]\ttraining's rmse: 0.770479\tvalid_1's rmse: 0.91329\n",
      "[444]\ttraining's rmse: 0.77036\tvalid_1's rmse: 0.913307\n",
      "[445]\ttraining's rmse: 0.770243\tvalid_1's rmse: 0.913309\n",
      "[446]\ttraining's rmse: 0.770124\tvalid_1's rmse: 0.913271\n",
      "[447]\ttraining's rmse: 0.769979\tvalid_1's rmse: 0.91334\n",
      "[448]\ttraining's rmse: 0.769859\tvalid_1's rmse: 0.913325\n",
      "[449]\ttraining's rmse: 0.769744\tvalid_1's rmse: 0.913341\n",
      "[450]\ttraining's rmse: 0.769667\tvalid_1's rmse: 0.913327\n",
      "[451]\ttraining's rmse: 0.769572\tvalid_1's rmse: 0.913324\n",
      "[452]\ttraining's rmse: 0.769464\tvalid_1's rmse: 0.913343\n",
      "[453]\ttraining's rmse: 0.76936\tvalid_1's rmse: 0.913332\n",
      "[454]\ttraining's rmse: 0.769269\tvalid_1's rmse: 0.9134\n",
      "[455]\ttraining's rmse: 0.769178\tvalid_1's rmse: 0.913376\n",
      "[456]\ttraining's rmse: 0.769073\tvalid_1's rmse: 0.913357\n",
      "[457]\ttraining's rmse: 0.768937\tvalid_1's rmse: 0.913378\n",
      "[458]\ttraining's rmse: 0.768796\tvalid_1's rmse: 0.913355\n",
      "[459]\ttraining's rmse: 0.768703\tvalid_1's rmse: 0.913358\n",
      "[460]\ttraining's rmse: 0.768599\tvalid_1's rmse: 0.913378\n",
      "[461]\ttraining's rmse: 0.768486\tvalid_1's rmse: 0.913373\n",
      "[462]\ttraining's rmse: 0.768379\tvalid_1's rmse: 0.913383\n",
      "[463]\ttraining's rmse: 0.768268\tvalid_1's rmse: 0.913419\n",
      "[464]\ttraining's rmse: 0.768183\tvalid_1's rmse: 0.91343\n",
      "[465]\ttraining's rmse: 0.768106\tvalid_1's rmse: 0.913447\n",
      "[466]\ttraining's rmse: 0.767975\tvalid_1's rmse: 0.913461\n",
      "[467]\ttraining's rmse: 0.767852\tvalid_1's rmse: 0.913449\n",
      "[468]\ttraining's rmse: 0.767436\tvalid_1's rmse: 0.913532\n",
      "[469]\ttraining's rmse: 0.767231\tvalid_1's rmse: 0.913525\n",
      "[470]\ttraining's rmse: 0.767107\tvalid_1's rmse: 0.913545\n",
      "[471]\ttraining's rmse: 0.767033\tvalid_1's rmse: 0.913519\n",
      "[472]\ttraining's rmse: 0.766924\tvalid_1's rmse: 0.913508\n",
      "[473]\ttraining's rmse: 0.766816\tvalid_1's rmse: 0.913512\n",
      "[474]\ttraining's rmse: 0.766729\tvalid_1's rmse: 0.913501\n",
      "[475]\ttraining's rmse: 0.766606\tvalid_1's rmse: 0.913531\n",
      "[476]\ttraining's rmse: 0.766522\tvalid_1's rmse: 0.913555\n",
      "[477]\ttraining's rmse: 0.766457\tvalid_1's rmse: 0.913536\n",
      "[478]\ttraining's rmse: 0.766321\tvalid_1's rmse: 0.91353\n",
      "[479]\ttraining's rmse: 0.766258\tvalid_1's rmse: 0.913539\n",
      "[480]\ttraining's rmse: 0.7661\tvalid_1's rmse: 0.913554\n",
      "[481]\ttraining's rmse: 0.765997\tvalid_1's rmse: 0.913539\n",
      "[482]\ttraining's rmse: 0.765901\tvalid_1's rmse: 0.91351\n",
      "[483]\ttraining's rmse: 0.765809\tvalid_1's rmse: 0.913507\n",
      "[484]\ttraining's rmse: 0.765727\tvalid_1's rmse: 0.913499\n",
      "[485]\ttraining's rmse: 0.765486\tvalid_1's rmse: 0.913495\n",
      "[486]\ttraining's rmse: 0.765399\tvalid_1's rmse: 0.913462\n",
      "[487]\ttraining's rmse: 0.765305\tvalid_1's rmse: 0.913457\n",
      "[488]\ttraining's rmse: 0.765236\tvalid_1's rmse: 0.913476\n",
      "[489]\ttraining's rmse: 0.765174\tvalid_1's rmse: 0.913472\n",
      "[490]\ttraining's rmse: 0.765072\tvalid_1's rmse: 0.913431\n",
      "[491]\ttraining's rmse: 0.764999\tvalid_1's rmse: 0.91341\n",
      "[492]\ttraining's rmse: 0.764868\tvalid_1's rmse: 0.91341\n",
      "[493]\ttraining's rmse: 0.764746\tvalid_1's rmse: 0.913393\n",
      "[494]\ttraining's rmse: 0.764652\tvalid_1's rmse: 0.913431\n",
      "[495]\ttraining's rmse: 0.764534\tvalid_1's rmse: 0.913446\n",
      "[496]\ttraining's rmse: 0.764438\tvalid_1's rmse: 0.913443\n",
      "[497]\ttraining's rmse: 0.764291\tvalid_1's rmse: 0.91341\n",
      "[498]\ttraining's rmse: 0.76419\tvalid_1's rmse: 0.913388\n",
      "[499]\ttraining's rmse: 0.764042\tvalid_1's rmse: 0.913397\n",
      "[500]\ttraining's rmse: 0.763955\tvalid_1's rmse: 0.913405\n",
      "[501]\ttraining's rmse: 0.763881\tvalid_1's rmse: 0.913384\n",
      "[502]\ttraining's rmse: 0.763781\tvalid_1's rmse: 0.913366\n",
      "[503]\ttraining's rmse: 0.763676\tvalid_1's rmse: 0.913334\n",
      "[504]\ttraining's rmse: 0.763383\tvalid_1's rmse: 0.913596\n",
      "[505]\ttraining's rmse: 0.763296\tvalid_1's rmse: 0.913553\n",
      "[506]\ttraining's rmse: 0.763229\tvalid_1's rmse: 0.913571\n",
      "[507]\ttraining's rmse: 0.763167\tvalid_1's rmse: 0.913555\n",
      "[508]\ttraining's rmse: 0.763073\tvalid_1's rmse: 0.913559\n",
      "[509]\ttraining's rmse: 0.763003\tvalid_1's rmse: 0.913566\n",
      "[510]\ttraining's rmse: 0.76294\tvalid_1's rmse: 0.913557\n",
      "[511]\ttraining's rmse: 0.76281\tvalid_1's rmse: 0.913554\n",
      "[512]\ttraining's rmse: 0.762689\tvalid_1's rmse: 0.91352\n",
      "[513]\ttraining's rmse: 0.762603\tvalid_1's rmse: 0.913513\n",
      "[514]\ttraining's rmse: 0.762529\tvalid_1's rmse: 0.913537\n",
      "[515]\ttraining's rmse: 0.762428\tvalid_1's rmse: 0.913535\n",
      "[516]\ttraining's rmse: 0.762317\tvalid_1's rmse: 0.913509\n",
      "[517]\ttraining's rmse: 0.762204\tvalid_1's rmse: 0.913469\n",
      "[518]\ttraining's rmse: 0.76185\tvalid_1's rmse: 0.913751\n",
      "[519]\ttraining's rmse: 0.761689\tvalid_1's rmse: 0.913714\n",
      "[520]\ttraining's rmse: 0.761574\tvalid_1's rmse: 0.913753\n",
      "[521]\ttraining's rmse: 0.761494\tvalid_1's rmse: 0.913765\n",
      "[522]\ttraining's rmse: 0.761377\tvalid_1's rmse: 0.913788\n",
      "[523]\ttraining's rmse: 0.76131\tvalid_1's rmse: 0.913767\n",
      "[524]\ttraining's rmse: 0.761217\tvalid_1's rmse: 0.913774\n",
      "[525]\ttraining's rmse: 0.761061\tvalid_1's rmse: 0.913687\n",
      "[526]\ttraining's rmse: 0.760975\tvalid_1's rmse: 0.913664\n",
      "[527]\ttraining's rmse: 0.760872\tvalid_1's rmse: 0.913749\n",
      "[528]\ttraining's rmse: 0.760766\tvalid_1's rmse: 0.913717\n",
      "[529]\ttraining's rmse: 0.760601\tvalid_1's rmse: 0.913701\n",
      "[530]\ttraining's rmse: 0.760516\tvalid_1's rmse: 0.91371\n",
      "[531]\ttraining's rmse: 0.76039\tvalid_1's rmse: 0.913632\n",
      "[532]\ttraining's rmse: 0.760252\tvalid_1's rmse: 0.91372\n",
      "[533]\ttraining's rmse: 0.760189\tvalid_1's rmse: 0.913738\n",
      "[534]\ttraining's rmse: 0.760132\tvalid_1's rmse: 0.913719\n",
      "[535]\ttraining's rmse: 0.760065\tvalid_1's rmse: 0.913762\n",
      "[536]\ttraining's rmse: 0.75999\tvalid_1's rmse: 0.91374\n",
      "[537]\ttraining's rmse: 0.759903\tvalid_1's rmse: 0.913759\n",
      "[538]\ttraining's rmse: 0.759789\tvalid_1's rmse: 0.913781\n",
      "[539]\ttraining's rmse: 0.759617\tvalid_1's rmse: 0.913737\n",
      "[540]\ttraining's rmse: 0.759505\tvalid_1's rmse: 0.913719\n",
      "[541]\ttraining's rmse: 0.759394\tvalid_1's rmse: 0.913729\n",
      "[542]\ttraining's rmse: 0.759307\tvalid_1's rmse: 0.913734\n",
      "[543]\ttraining's rmse: 0.759231\tvalid_1's rmse: 0.91376\n",
      "[544]\ttraining's rmse: 0.759165\tvalid_1's rmse: 0.913765\n",
      "[545]\ttraining's rmse: 0.759077\tvalid_1's rmse: 0.913759\n",
      "[546]\ttraining's rmse: 0.759023\tvalid_1's rmse: 0.91373\n",
      "[547]\ttraining's rmse: 0.758926\tvalid_1's rmse: 0.913738\n",
      "[548]\ttraining's rmse: 0.758705\tvalid_1's rmse: 0.913698\n",
      "[549]\ttraining's rmse: 0.758638\tvalid_1's rmse: 0.913706\n",
      "[550]\ttraining's rmse: 0.758516\tvalid_1's rmse: 0.913671\n",
      "[551]\ttraining's rmse: 0.758413\tvalid_1's rmse: 0.913683\n",
      "[552]\ttraining's rmse: 0.758301\tvalid_1's rmse: 0.913653\n",
      "[553]\ttraining's rmse: 0.758234\tvalid_1's rmse: 0.913637\n",
      "[554]\ttraining's rmse: 0.758163\tvalid_1's rmse: 0.913625\n",
      "[555]\ttraining's rmse: 0.758064\tvalid_1's rmse: 0.913636\n",
      "[556]\ttraining's rmse: 0.757949\tvalid_1's rmse: 0.913641\n",
      "[557]\ttraining's rmse: 0.757861\tvalid_1's rmse: 0.913672\n",
      "[558]\ttraining's rmse: 0.757801\tvalid_1's rmse: 0.913692\n",
      "[559]\ttraining's rmse: 0.75769\tvalid_1's rmse: 0.913671\n",
      "[560]\ttraining's rmse: 0.757608\tvalid_1's rmse: 0.913666\n",
      "[561]\ttraining's rmse: 0.757542\tvalid_1's rmse: 0.913666\n",
      "[562]\ttraining's rmse: 0.757481\tvalid_1's rmse: 0.913652\n",
      "[563]\ttraining's rmse: 0.757399\tvalid_1's rmse: 0.913673\n",
      "[564]\ttraining's rmse: 0.757287\tvalid_1's rmse: 0.913664\n",
      "[565]\ttraining's rmse: 0.757207\tvalid_1's rmse: 0.913655\n",
      "[566]\ttraining's rmse: 0.757125\tvalid_1's rmse: 0.913656\n",
      "[567]\ttraining's rmse: 0.757036\tvalid_1's rmse: 0.913638\n",
      "[568]\ttraining's rmse: 0.75694\tvalid_1's rmse: 0.913585\n",
      "[569]\ttraining's rmse: 0.756888\tvalid_1's rmse: 0.913581\n",
      "[570]\ttraining's rmse: 0.75677\tvalid_1's rmse: 0.913573\n",
      "[571]\ttraining's rmse: 0.756654\tvalid_1's rmse: 0.913562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[572]\ttraining's rmse: 0.756598\tvalid_1's rmse: 0.913563\n",
      "[573]\ttraining's rmse: 0.756527\tvalid_1's rmse: 0.913557\n",
      "[574]\ttraining's rmse: 0.756466\tvalid_1's rmse: 0.913553\n",
      "[575]\ttraining's rmse: 0.756391\tvalid_1's rmse: 0.913559\n",
      "[576]\ttraining's rmse: 0.756313\tvalid_1's rmse: 0.913574\n",
      "[577]\ttraining's rmse: 0.75622\tvalid_1's rmse: 0.913469\n",
      "[578]\ttraining's rmse: 0.756173\tvalid_1's rmse: 0.913463\n",
      "[579]\ttraining's rmse: 0.756114\tvalid_1's rmse: 0.913474\n",
      "[580]\ttraining's rmse: 0.756024\tvalid_1's rmse: 0.913502\n",
      "[581]\ttraining's rmse: 0.755937\tvalid_1's rmse: 0.913515\n",
      "[582]\ttraining's rmse: 0.755784\tvalid_1's rmse: 0.913444\n",
      "[583]\ttraining's rmse: 0.755704\tvalid_1's rmse: 0.913453\n",
      "[584]\ttraining's rmse: 0.755642\tvalid_1's rmse: 0.913461\n",
      "[585]\ttraining's rmse: 0.755567\tvalid_1's rmse: 0.913428\n",
      "[586]\ttraining's rmse: 0.755502\tvalid_1's rmse: 0.913416\n",
      "[587]\ttraining's rmse: 0.755158\tvalid_1's rmse: 0.913334\n",
      "[588]\ttraining's rmse: 0.755106\tvalid_1's rmse: 0.913334\n",
      "[589]\ttraining's rmse: 0.754972\tvalid_1's rmse: 0.913288\n",
      "[590]\ttraining's rmse: 0.754869\tvalid_1's rmse: 0.913315\n",
      "[591]\ttraining's rmse: 0.754746\tvalid_1's rmse: 0.913273\n",
      "[592]\ttraining's rmse: 0.75461\tvalid_1's rmse: 0.913308\n",
      "[593]\ttraining's rmse: 0.754511\tvalid_1's rmse: 0.913262\n",
      "[594]\ttraining's rmse: 0.754444\tvalid_1's rmse: 0.913276\n",
      "[595]\ttraining's rmse: 0.754388\tvalid_1's rmse: 0.91327\n",
      "[596]\ttraining's rmse: 0.754314\tvalid_1's rmse: 0.913284\n",
      "[597]\ttraining's rmse: 0.754203\tvalid_1's rmse: 0.913323\n",
      "[598]\ttraining's rmse: 0.754131\tvalid_1's rmse: 0.913355\n",
      "[599]\ttraining's rmse: 0.754029\tvalid_1's rmse: 0.91337\n",
      "[600]\ttraining's rmse: 0.753967\tvalid_1's rmse: 0.91337\n",
      "[601]\ttraining's rmse: 0.753879\tvalid_1's rmse: 0.913375\n",
      "[602]\ttraining's rmse: 0.753825\tvalid_1's rmse: 0.913375\n",
      "[603]\ttraining's rmse: 0.753729\tvalid_1's rmse: 0.913361\n",
      "[604]\ttraining's rmse: 0.75365\tvalid_1's rmse: 0.913359\n",
      "[605]\ttraining's rmse: 0.753514\tvalid_1's rmse: 0.913318\n",
      "[606]\ttraining's rmse: 0.753293\tvalid_1's rmse: 0.913324\n",
      "[607]\ttraining's rmse: 0.753219\tvalid_1's rmse: 0.913333\n",
      "[608]\ttraining's rmse: 0.753131\tvalid_1's rmse: 0.91339\n",
      "[609]\ttraining's rmse: 0.753017\tvalid_1's rmse: 0.913846\n",
      "[610]\ttraining's rmse: 0.752946\tvalid_1's rmse: 0.913867\n",
      "[611]\ttraining's rmse: 0.752891\tvalid_1's rmse: 0.913866\n",
      "[612]\ttraining's rmse: 0.75281\tvalid_1's rmse: 0.913863\n",
      "[613]\ttraining's rmse: 0.752749\tvalid_1's rmse: 0.913846\n",
      "[614]\ttraining's rmse: 0.752687\tvalid_1's rmse: 0.913864\n",
      "[615]\ttraining's rmse: 0.752628\tvalid_1's rmse: 0.913842\n",
      "[616]\ttraining's rmse: 0.75256\tvalid_1's rmse: 0.91384\n",
      "[617]\ttraining's rmse: 0.752465\tvalid_1's rmse: 0.91374\n",
      "[618]\ttraining's rmse: 0.752406\tvalid_1's rmse: 0.913724\n",
      "[619]\ttraining's rmse: 0.752335\tvalid_1's rmse: 0.913713\n",
      "[620]\ttraining's rmse: 0.752267\tvalid_1's rmse: 0.913743\n",
      "[621]\ttraining's rmse: 0.752198\tvalid_1's rmse: 0.913773\n",
      "[622]\ttraining's rmse: 0.752111\tvalid_1's rmse: 0.913765\n",
      "[623]\ttraining's rmse: 0.752025\tvalid_1's rmse: 0.913799\n",
      "[624]\ttraining's rmse: 0.751943\tvalid_1's rmse: 0.913804\n",
      "[625]\ttraining's rmse: 0.751865\tvalid_1's rmse: 0.91381\n",
      "[626]\ttraining's rmse: 0.75177\tvalid_1's rmse: 0.913839\n",
      "[627]\ttraining's rmse: 0.751716\tvalid_1's rmse: 0.913825\n",
      "[628]\ttraining's rmse: 0.751652\tvalid_1's rmse: 0.913848\n",
      "[629]\ttraining's rmse: 0.751577\tvalid_1's rmse: 0.913865\n",
      "[630]\ttraining's rmse: 0.751505\tvalid_1's rmse: 0.913879\n",
      "[631]\ttraining's rmse: 0.751423\tvalid_1's rmse: 0.913882\n",
      "[632]\ttraining's rmse: 0.751358\tvalid_1's rmse: 0.913879\n",
      "[633]\ttraining's rmse: 0.751296\tvalid_1's rmse: 0.913888\n",
      "[634]\ttraining's rmse: 0.751218\tvalid_1's rmse: 0.913899\n",
      "[635]\ttraining's rmse: 0.751173\tvalid_1's rmse: 0.913894\n",
      "[636]\ttraining's rmse: 0.751128\tvalid_1's rmse: 0.913898\n",
      "[637]\ttraining's rmse: 0.751036\tvalid_1's rmse: 0.913916\n",
      "[638]\ttraining's rmse: 0.750953\tvalid_1's rmse: 0.913916\n",
      "[639]\ttraining's rmse: 0.750904\tvalid_1's rmse: 0.913907\n",
      "[640]\ttraining's rmse: 0.750827\tvalid_1's rmse: 0.9139\n",
      "[641]\ttraining's rmse: 0.75075\tvalid_1's rmse: 0.913931\n",
      "[642]\ttraining's rmse: 0.7506\tvalid_1's rmse: 0.913936\n",
      "[643]\ttraining's rmse: 0.7505\tvalid_1's rmse: 0.913894\n",
      "[644]\ttraining's rmse: 0.750426\tvalid_1's rmse: 0.913904\n",
      "[645]\ttraining's rmse: 0.750342\tvalid_1's rmse: 0.913991\n",
      "[646]\ttraining's rmse: 0.750278\tvalid_1's rmse: 0.913972\n",
      "[647]\ttraining's rmse: 0.750158\tvalid_1's rmse: 0.913997\n",
      "[648]\ttraining's rmse: 0.75011\tvalid_1's rmse: 0.913995\n",
      "[649]\ttraining's rmse: 0.749989\tvalid_1's rmse: 0.913942\n",
      "[650]\ttraining's rmse: 0.749932\tvalid_1's rmse: 0.913942\n",
      "[651]\ttraining's rmse: 0.749861\tvalid_1's rmse: 0.91395\n",
      "[652]\ttraining's rmse: 0.74978\tvalid_1's rmse: 0.913935\n",
      "[653]\ttraining's rmse: 0.749711\tvalid_1's rmse: 0.913921\n",
      "[654]\ttraining's rmse: 0.749655\tvalid_1's rmse: 0.913927\n",
      "[655]\ttraining's rmse: 0.749591\tvalid_1's rmse: 0.913923\n",
      "[656]\ttraining's rmse: 0.749507\tvalid_1's rmse: 0.91392\n",
      "[657]\ttraining's rmse: 0.749432\tvalid_1's rmse: 0.913902\n",
      "[658]\ttraining's rmse: 0.749358\tvalid_1's rmse: 0.913899\n",
      "[659]\ttraining's rmse: 0.749284\tvalid_1's rmse: 0.913897\n",
      "[660]\ttraining's rmse: 0.749237\tvalid_1's rmse: 0.913901\n",
      "[661]\ttraining's rmse: 0.749135\tvalid_1's rmse: 0.913846\n",
      "[662]\ttraining's rmse: 0.749079\tvalid_1's rmse: 0.913852\n",
      "[663]\ttraining's rmse: 0.749022\tvalid_1's rmse: 0.913836\n",
      "[664]\ttraining's rmse: 0.74894\tvalid_1's rmse: 0.913847\n",
      "[665]\ttraining's rmse: 0.748868\tvalid_1's rmse: 0.91389\n",
      "[666]\ttraining's rmse: 0.748806\tvalid_1's rmse: 0.913865\n",
      "[667]\ttraining's rmse: 0.748743\tvalid_1's rmse: 0.913863\n",
      "[668]\ttraining's rmse: 0.748669\tvalid_1's rmse: 0.913867\n",
      "[669]\ttraining's rmse: 0.74859\tvalid_1's rmse: 0.913899\n",
      "[670]\ttraining's rmse: 0.748532\tvalid_1's rmse: 0.913887\n",
      "[671]\ttraining's rmse: 0.748454\tvalid_1's rmse: 0.913889\n",
      "[672]\ttraining's rmse: 0.748381\tvalid_1's rmse: 0.913926\n",
      "[673]\ttraining's rmse: 0.748303\tvalid_1's rmse: 0.91393\n",
      "[674]\ttraining's rmse: 0.74826\tvalid_1's rmse: 0.913929\n",
      "[675]\ttraining's rmse: 0.748197\tvalid_1's rmse: 0.914004\n",
      "[676]\ttraining's rmse: 0.74812\tvalid_1's rmse: 0.914047\n",
      "[677]\ttraining's rmse: 0.748074\tvalid_1's rmse: 0.914062\n",
      "[678]\ttraining's rmse: 0.748025\tvalid_1's rmse: 0.914131\n",
      "[679]\ttraining's rmse: 0.747968\tvalid_1's rmse: 0.914124\n",
      "[680]\ttraining's rmse: 0.74792\tvalid_1's rmse: 0.91414\n",
      "[681]\ttraining's rmse: 0.747852\tvalid_1's rmse: 0.914126\n",
      "[682]\ttraining's rmse: 0.747771\tvalid_1's rmse: 0.914111\n",
      "[683]\ttraining's rmse: 0.747707\tvalid_1's rmse: 0.91412\n",
      "[684]\ttraining's rmse: 0.747653\tvalid_1's rmse: 0.914128\n",
      "[685]\ttraining's rmse: 0.747612\tvalid_1's rmse: 0.914119\n",
      "[686]\ttraining's rmse: 0.747552\tvalid_1's rmse: 0.914106\n",
      "[687]\ttraining's rmse: 0.747423\tvalid_1's rmse: 0.91402\n",
      "[688]\ttraining's rmse: 0.747327\tvalid_1's rmse: 0.914089\n",
      "[689]\ttraining's rmse: 0.747282\tvalid_1's rmse: 0.914074\n",
      "[690]\ttraining's rmse: 0.74723\tvalid_1's rmse: 0.914062\n",
      "[691]\ttraining's rmse: 0.747186\tvalid_1's rmse: 0.914047\n",
      "[692]\ttraining's rmse: 0.747121\tvalid_1's rmse: 0.914039\n",
      "[693]\ttraining's rmse: 0.747065\tvalid_1's rmse: 0.914048\n",
      "[694]\ttraining's rmse: 0.747008\tvalid_1's rmse: 0.914081\n",
      "[695]\ttraining's rmse: 0.746943\tvalid_1's rmse: 0.91408\n",
      "[696]\ttraining's rmse: 0.746838\tvalid_1's rmse: 0.91405\n",
      "[697]\ttraining's rmse: 0.746794\tvalid_1's rmse: 0.914052\n",
      "[698]\ttraining's rmse: 0.74674\tvalid_1's rmse: 0.914056\n",
      "[699]\ttraining's rmse: 0.74668\tvalid_1's rmse: 0.914055\n",
      "[700]\ttraining's rmse: 0.746605\tvalid_1's rmse: 0.91411\n",
      "[701]\ttraining's rmse: 0.746561\tvalid_1's rmse: 0.914174\n",
      "[702]\ttraining's rmse: 0.746505\tvalid_1's rmse: 0.914171\n",
      "[703]\ttraining's rmse: 0.746464\tvalid_1's rmse: 0.914153\n",
      "[704]\ttraining's rmse: 0.746405\tvalid_1's rmse: 0.914174\n",
      "[705]\ttraining's rmse: 0.746325\tvalid_1's rmse: 0.914165\n",
      "[706]\ttraining's rmse: 0.746274\tvalid_1's rmse: 0.914161\n",
      "[707]\ttraining's rmse: 0.746207\tvalid_1's rmse: 0.914148\n",
      "[708]\ttraining's rmse: 0.746144\tvalid_1's rmse: 0.914119\n",
      "[709]\ttraining's rmse: 0.746087\tvalid_1's rmse: 0.914155\n",
      "[710]\ttraining's rmse: 0.746025\tvalid_1's rmse: 0.914131\n",
      "[711]\ttraining's rmse: 0.745965\tvalid_1's rmse: 0.914152\n",
      "[712]\ttraining's rmse: 0.74591\tvalid_1's rmse: 0.914127\n",
      "[713]\ttraining's rmse: 0.745868\tvalid_1's rmse: 0.914106\n",
      "[714]\ttraining's rmse: 0.745802\tvalid_1's rmse: 0.9141\n",
      "[715]\ttraining's rmse: 0.745756\tvalid_1's rmse: 0.914119\n",
      "[716]\ttraining's rmse: 0.745692\tvalid_1's rmse: 0.914081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[717]\ttraining's rmse: 0.745644\tvalid_1's rmse: 0.91407\n",
      "[718]\ttraining's rmse: 0.74557\tvalid_1's rmse: 0.914097\n",
      "[719]\ttraining's rmse: 0.745494\tvalid_1's rmse: 0.914102\n",
      "[720]\ttraining's rmse: 0.745445\tvalid_1's rmse: 0.914095\n",
      "[721]\ttraining's rmse: 0.745397\tvalid_1's rmse: 0.914089\n",
      "[722]\ttraining's rmse: 0.745313\tvalid_1's rmse: 0.914068\n",
      "[723]\ttraining's rmse: 0.74524\tvalid_1's rmse: 0.914095\n",
      "[724]\ttraining's rmse: 0.745188\tvalid_1's rmse: 0.914082\n",
      "[725]\ttraining's rmse: 0.74514\tvalid_1's rmse: 0.914085\n",
      "[726]\ttraining's rmse: 0.745064\tvalid_1's rmse: 0.91407\n",
      "[727]\ttraining's rmse: 0.744991\tvalid_1's rmse: 0.914088\n",
      "[728]\ttraining's rmse: 0.744932\tvalid_1's rmse: 0.914081\n",
      "[729]\ttraining's rmse: 0.744874\tvalid_1's rmse: 0.914079\n",
      "[730]\ttraining's rmse: 0.744528\tvalid_1's rmse: 0.914077\n",
      "[731]\ttraining's rmse: 0.744478\tvalid_1's rmse: 0.914084\n",
      "[732]\ttraining's rmse: 0.744431\tvalid_1's rmse: 0.914087\n",
      "[733]\ttraining's rmse: 0.744386\tvalid_1's rmse: 0.914072\n",
      "[734]\ttraining's rmse: 0.744305\tvalid_1's rmse: 0.914081\n",
      "[735]\ttraining's rmse: 0.744252\tvalid_1's rmse: 0.9141\n",
      "[736]\ttraining's rmse: 0.744199\tvalid_1's rmse: 0.914137\n",
      "[737]\ttraining's rmse: 0.744118\tvalid_1's rmse: 0.914134\n",
      "[738]\ttraining's rmse: 0.744044\tvalid_1's rmse: 0.914138\n",
      "[739]\ttraining's rmse: 0.743977\tvalid_1's rmse: 0.91415\n",
      "[740]\ttraining's rmse: 0.743922\tvalid_1's rmse: 0.914156\n",
      "[741]\ttraining's rmse: 0.74383\tvalid_1's rmse: 0.914121\n",
      "[742]\ttraining's rmse: 0.743755\tvalid_1's rmse: 0.914112\n",
      "[743]\ttraining's rmse: 0.743654\tvalid_1's rmse: 0.914106\n",
      "[744]\ttraining's rmse: 0.743564\tvalid_1's rmse: 0.914113\n",
      "[745]\ttraining's rmse: 0.743496\tvalid_1's rmse: 0.914092\n",
      "[746]\ttraining's rmse: 0.74344\tvalid_1's rmse: 0.914176\n",
      "[747]\ttraining's rmse: 0.743315\tvalid_1's rmse: 0.914137\n",
      "[748]\ttraining's rmse: 0.743244\tvalid_1's rmse: 0.914163\n",
      "[749]\ttraining's rmse: 0.743181\tvalid_1's rmse: 0.914172\n",
      "[750]\ttraining's rmse: 0.74313\tvalid_1's rmse: 0.914168\n",
      "[751]\ttraining's rmse: 0.743072\tvalid_1's rmse: 0.914196\n",
      "[752]\ttraining's rmse: 0.743012\tvalid_1's rmse: 0.914226\n",
      "[753]\ttraining's rmse: 0.742949\tvalid_1's rmse: 0.914228\n",
      "[754]\ttraining's rmse: 0.742791\tvalid_1's rmse: 0.913952\n",
      "[755]\ttraining's rmse: 0.74254\tvalid_1's rmse: 0.914167\n",
      "[756]\ttraining's rmse: 0.742484\tvalid_1's rmse: 0.914158\n",
      "[757]\ttraining's rmse: 0.742434\tvalid_1's rmse: 0.914138\n",
      "[758]\ttraining's rmse: 0.742357\tvalid_1's rmse: 0.913981\n",
      "[759]\ttraining's rmse: 0.742276\tvalid_1's rmse: 0.91385\n",
      "[760]\ttraining's rmse: 0.742222\tvalid_1's rmse: 0.913855\n",
      "[761]\ttraining's rmse: 0.742184\tvalid_1's rmse: 0.913857\n",
      "[762]\ttraining's rmse: 0.742138\tvalid_1's rmse: 0.913867\n",
      "[763]\ttraining's rmse: 0.742078\tvalid_1's rmse: 0.913858\n",
      "[764]\ttraining's rmse: 0.742021\tvalid_1's rmse: 0.91384\n",
      "[765]\ttraining's rmse: 0.74196\tvalid_1's rmse: 0.913838\n",
      "[766]\ttraining's rmse: 0.741921\tvalid_1's rmse: 0.913829\n",
      "[767]\ttraining's rmse: 0.741852\tvalid_1's rmse: 0.913846\n",
      "[768]\ttraining's rmse: 0.741808\tvalid_1's rmse: 0.913853\n",
      "[769]\ttraining's rmse: 0.741769\tvalid_1's rmse: 0.913805\n",
      "[770]\ttraining's rmse: 0.741664\tvalid_1's rmse: 0.913773\n",
      "[771]\ttraining's rmse: 0.741621\tvalid_1's rmse: 0.913761\n",
      "[772]\ttraining's rmse: 0.741552\tvalid_1's rmse: 0.91376\n",
      "[773]\ttraining's rmse: 0.741505\tvalid_1's rmse: 0.913771\n",
      "[774]\ttraining's rmse: 0.741451\tvalid_1's rmse: 0.913767\n",
      "[775]\ttraining's rmse: 0.741379\tvalid_1's rmse: 0.913762\n",
      "[776]\ttraining's rmse: 0.741323\tvalid_1's rmse: 0.913764\n",
      "[777]\ttraining's rmse: 0.741226\tvalid_1's rmse: 0.913689\n",
      "[778]\ttraining's rmse: 0.741144\tvalid_1's rmse: 0.913676\n",
      "[779]\ttraining's rmse: 0.741076\tvalid_1's rmse: 0.913685\n",
      "[780]\ttraining's rmse: 0.741012\tvalid_1's rmse: 0.913648\n",
      "[781]\ttraining's rmse: 0.740958\tvalid_1's rmse: 0.913638\n",
      "[782]\ttraining's rmse: 0.740907\tvalid_1's rmse: 0.913649\n",
      "[783]\ttraining's rmse: 0.740836\tvalid_1's rmse: 0.913654\n",
      "[784]\ttraining's rmse: 0.740783\tvalid_1's rmse: 0.91367\n",
      "[785]\ttraining's rmse: 0.74072\tvalid_1's rmse: 0.913672\n",
      "[786]\ttraining's rmse: 0.740669\tvalid_1's rmse: 0.913705\n",
      "[787]\ttraining's rmse: 0.740632\tvalid_1's rmse: 0.913696\n",
      "[788]\ttraining's rmse: 0.740584\tvalid_1's rmse: 0.913691\n",
      "[789]\ttraining's rmse: 0.740533\tvalid_1's rmse: 0.913702\n",
      "[790]\ttraining's rmse: 0.740407\tvalid_1's rmse: 0.913619\n",
      "[791]\ttraining's rmse: 0.740367\tvalid_1's rmse: 0.91363\n",
      "[792]\ttraining's rmse: 0.740331\tvalid_1's rmse: 0.91363\n",
      "[793]\ttraining's rmse: 0.740247\tvalid_1's rmse: 0.913641\n",
      "[794]\ttraining's rmse: 0.7402\tvalid_1's rmse: 0.913636\n",
      "[795]\ttraining's rmse: 0.740162\tvalid_1's rmse: 0.913651\n",
      "[796]\ttraining's rmse: 0.740103\tvalid_1's rmse: 0.913673\n",
      "[797]\ttraining's rmse: 0.740051\tvalid_1's rmse: 0.913665\n",
      "[798]\ttraining's rmse: 0.739998\tvalid_1's rmse: 0.913727\n",
      "[799]\ttraining's rmse: 0.739934\tvalid_1's rmse: 0.913718\n",
      "[800]\ttraining's rmse: 0.739894\tvalid_1's rmse: 0.91371\n",
      "[801]\ttraining's rmse: 0.739856\tvalid_1's rmse: 0.913707\n",
      "[802]\ttraining's rmse: 0.739812\tvalid_1's rmse: 0.913697\n",
      "[803]\ttraining's rmse: 0.739772\tvalid_1's rmse: 0.913689\n",
      "[804]\ttraining's rmse: 0.739738\tvalid_1's rmse: 0.91369\n",
      "[805]\ttraining's rmse: 0.739684\tvalid_1's rmse: 0.913686\n",
      "[806]\ttraining's rmse: 0.739609\tvalid_1's rmse: 0.913684\n",
      "[807]\ttraining's rmse: 0.739472\tvalid_1's rmse: 0.91393\n",
      "[808]\ttraining's rmse: 0.739406\tvalid_1's rmse: 0.91393\n",
      "[809]\ttraining's rmse: 0.73935\tvalid_1's rmse: 0.913934\n",
      "[810]\ttraining's rmse: 0.73931\tvalid_1's rmse: 0.91394\n",
      "[811]\ttraining's rmse: 0.739269\tvalid_1's rmse: 0.913963\n",
      "[812]\ttraining's rmse: 0.739209\tvalid_1's rmse: 0.913979\n",
      "[813]\ttraining's rmse: 0.739167\tvalid_1's rmse: 0.913977\n",
      "[814]\ttraining's rmse: 0.73913\tvalid_1's rmse: 0.913979\n",
      "[815]\ttraining's rmse: 0.739011\tvalid_1's rmse: 0.913928\n",
      "[816]\ttraining's rmse: 0.738964\tvalid_1's rmse: 0.913931\n",
      "[817]\ttraining's rmse: 0.738914\tvalid_1's rmse: 0.913942\n",
      "[818]\ttraining's rmse: 0.738884\tvalid_1's rmse: 0.913934\n",
      "[819]\ttraining's rmse: 0.738509\tvalid_1's rmse: 0.914291\n",
      "[820]\ttraining's rmse: 0.738466\tvalid_1's rmse: 0.914284\n",
      "[821]\ttraining's rmse: 0.738434\tvalid_1's rmse: 0.914283\n",
      "[822]\ttraining's rmse: 0.738361\tvalid_1's rmse: 0.91429\n",
      "[823]\ttraining's rmse: 0.738324\tvalid_1's rmse: 0.914288\n",
      "[824]\ttraining's rmse: 0.738243\tvalid_1's rmse: 0.914266\n",
      "[825]\ttraining's rmse: 0.738205\tvalid_1's rmse: 0.914272\n",
      "[826]\ttraining's rmse: 0.738109\tvalid_1's rmse: 0.914268\n",
      "[827]\ttraining's rmse: 0.73802\tvalid_1's rmse: 0.914295\n",
      "[828]\ttraining's rmse: 0.737951\tvalid_1's rmse: 0.914266\n",
      "[829]\ttraining's rmse: 0.737891\tvalid_1's rmse: 0.914268\n",
      "[830]\ttraining's rmse: 0.737774\tvalid_1's rmse: 0.914241\n",
      "[831]\ttraining's rmse: 0.737697\tvalid_1's rmse: 0.914248\n",
      "[832]\ttraining's rmse: 0.737651\tvalid_1's rmse: 0.914237\n",
      "[833]\ttraining's rmse: 0.737596\tvalid_1's rmse: 0.914248\n",
      "[834]\ttraining's rmse: 0.737426\tvalid_1's rmse: 0.914237\n",
      "[835]\ttraining's rmse: 0.737381\tvalid_1's rmse: 0.914238\n",
      "[836]\ttraining's rmse: 0.737334\tvalid_1's rmse: 0.91421\n",
      "[837]\ttraining's rmse: 0.737289\tvalid_1's rmse: 0.914227\n",
      "[838]\ttraining's rmse: 0.737247\tvalid_1's rmse: 0.914223\n",
      "[839]\ttraining's rmse: 0.73721\tvalid_1's rmse: 0.914221\n",
      "[840]\ttraining's rmse: 0.737155\tvalid_1's rmse: 0.914238\n",
      "[841]\ttraining's rmse: 0.737114\tvalid_1's rmse: 0.91422\n",
      "[842]\ttraining's rmse: 0.737057\tvalid_1's rmse: 0.914225\n",
      "[843]\ttraining's rmse: 0.736984\tvalid_1's rmse: 0.914224\n",
      "[844]\ttraining's rmse: 0.736933\tvalid_1's rmse: 0.914207\n",
      "[845]\ttraining's rmse: 0.736887\tvalid_1's rmse: 0.914248\n",
      "[846]\ttraining's rmse: 0.736847\tvalid_1's rmse: 0.914237\n",
      "[847]\ttraining's rmse: 0.736809\tvalid_1's rmse: 0.914259\n",
      "[848]\ttraining's rmse: 0.736754\tvalid_1's rmse: 0.914266\n",
      "[849]\ttraining's rmse: 0.736712\tvalid_1's rmse: 0.91426\n",
      "[850]\ttraining's rmse: 0.736579\tvalid_1's rmse: 0.91448\n",
      "[851]\ttraining's rmse: 0.736522\tvalid_1's rmse: 0.914464\n",
      "[852]\ttraining's rmse: 0.736478\tvalid_1's rmse: 0.914495\n",
      "[853]\ttraining's rmse: 0.736414\tvalid_1's rmse: 0.914529\n",
      "[854]\ttraining's rmse: 0.736367\tvalid_1's rmse: 0.914524\n",
      "[855]\ttraining's rmse: 0.736332\tvalid_1's rmse: 0.914518\n",
      "[856]\ttraining's rmse: 0.736205\tvalid_1's rmse: 0.914462\n",
      "[857]\ttraining's rmse: 0.736162\tvalid_1's rmse: 0.914474\n",
      "[858]\ttraining's rmse: 0.736106\tvalid_1's rmse: 0.914474\n",
      "[859]\ttraining's rmse: 0.736056\tvalid_1's rmse: 0.91447\n",
      "[860]\ttraining's rmse: 0.73598\tvalid_1's rmse: 0.914473\n",
      "[861]\ttraining's rmse: 0.735931\tvalid_1's rmse: 0.914486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[862]\ttraining's rmse: 0.735883\tvalid_1's rmse: 0.914557\n",
      "[863]\ttraining's rmse: 0.735623\tvalid_1's rmse: 0.914476\n",
      "[864]\ttraining's rmse: 0.735568\tvalid_1's rmse: 0.914539\n",
      "[865]\ttraining's rmse: 0.735525\tvalid_1's rmse: 0.914533\n",
      "[866]\ttraining's rmse: 0.735469\tvalid_1's rmse: 0.914548\n",
      "[867]\ttraining's rmse: 0.73543\tvalid_1's rmse: 0.91455\n",
      "[868]\ttraining's rmse: 0.735384\tvalid_1's rmse: 0.914555\n",
      "[869]\ttraining's rmse: 0.735343\tvalid_1's rmse: 0.914545\n",
      "[870]\ttraining's rmse: 0.735304\tvalid_1's rmse: 0.914535\n",
      "[871]\ttraining's rmse: 0.735238\tvalid_1's rmse: 0.914493\n",
      "[872]\ttraining's rmse: 0.735189\tvalid_1's rmse: 0.914489\n",
      "[873]\ttraining's rmse: 0.735129\tvalid_1's rmse: 0.914487\n",
      "[874]\ttraining's rmse: 0.735042\tvalid_1's rmse: 0.914494\n",
      "[875]\ttraining's rmse: 0.734992\tvalid_1's rmse: 0.914514\n",
      "[876]\ttraining's rmse: 0.734939\tvalid_1's rmse: 0.914529\n",
      "[877]\ttraining's rmse: 0.734888\tvalid_1's rmse: 0.914476\n",
      "[878]\ttraining's rmse: 0.734841\tvalid_1's rmse: 0.914479\n",
      "[879]\ttraining's rmse: 0.734788\tvalid_1's rmse: 0.914497\n",
      "[880]\ttraining's rmse: 0.734744\tvalid_1's rmse: 0.914509\n",
      "[881]\ttraining's rmse: 0.734691\tvalid_1's rmse: 0.9145\n",
      "[882]\ttraining's rmse: 0.734648\tvalid_1's rmse: 0.91451\n",
      "[883]\ttraining's rmse: 0.734613\tvalid_1's rmse: 0.914511\n",
      "[884]\ttraining's rmse: 0.734572\tvalid_1's rmse: 0.914512\n",
      "[885]\ttraining's rmse: 0.734532\tvalid_1's rmse: 0.914485\n",
      "[886]\ttraining's rmse: 0.734495\tvalid_1's rmse: 0.914497\n",
      "[887]\ttraining's rmse: 0.734433\tvalid_1's rmse: 0.914506\n",
      "[888]\ttraining's rmse: 0.734392\tvalid_1's rmse: 0.914506\n",
      "[889]\ttraining's rmse: 0.734333\tvalid_1's rmse: 0.91448\n",
      "[890]\ttraining's rmse: 0.734287\tvalid_1's rmse: 0.914518\n",
      "[891]\ttraining's rmse: 0.734239\tvalid_1's rmse: 0.914512\n",
      "[892]\ttraining's rmse: 0.734194\tvalid_1's rmse: 0.914527\n",
      "[893]\ttraining's rmse: 0.734157\tvalid_1's rmse: 0.914509\n",
      "[894]\ttraining's rmse: 0.734121\tvalid_1's rmse: 0.914513\n",
      "[895]\ttraining's rmse: 0.734045\tvalid_1's rmse: 0.914513\n",
      "[896]\ttraining's rmse: 0.73401\tvalid_1's rmse: 0.914511\n",
      "[897]\ttraining's rmse: 0.733972\tvalid_1's rmse: 0.91451\n",
      "[898]\ttraining's rmse: 0.733934\tvalid_1's rmse: 0.914509\n",
      "[899]\ttraining's rmse: 0.733889\tvalid_1's rmse: 0.914498\n",
      "[900]\ttraining's rmse: 0.733836\tvalid_1's rmse: 0.914492\n",
      "[901]\ttraining's rmse: 0.733796\tvalid_1's rmse: 0.914488\n",
      "[902]\ttraining's rmse: 0.73376\tvalid_1's rmse: 0.914477\n",
      "[903]\ttraining's rmse: 0.733713\tvalid_1's rmse: 0.914468\n",
      "[904]\ttraining's rmse: 0.733651\tvalid_1's rmse: 0.914449\n",
      "[905]\ttraining's rmse: 0.733605\tvalid_1's rmse: 0.914446\n",
      "[906]\ttraining's rmse: 0.733558\tvalid_1's rmse: 0.91444\n",
      "[907]\ttraining's rmse: 0.73352\tvalid_1's rmse: 0.914437\n",
      "[908]\ttraining's rmse: 0.733453\tvalid_1's rmse: 0.914415\n",
      "[909]\ttraining's rmse: 0.733416\tvalid_1's rmse: 0.914412\n",
      "[910]\ttraining's rmse: 0.733373\tvalid_1's rmse: 0.914404\n",
      "[911]\ttraining's rmse: 0.733323\tvalid_1's rmse: 0.914372\n",
      "[912]\ttraining's rmse: 0.733289\tvalid_1's rmse: 0.914356\n",
      "[913]\ttraining's rmse: 0.73325\tvalid_1's rmse: 0.91431\n",
      "[914]\ttraining's rmse: 0.733191\tvalid_1's rmse: 0.914295\n",
      "[915]\ttraining's rmse: 0.733152\tvalid_1's rmse: 0.914286\n",
      "[916]\ttraining's rmse: 0.733113\tvalid_1's rmse: 0.914275\n",
      "[917]\ttraining's rmse: 0.733068\tvalid_1's rmse: 0.914285\n",
      "[918]\ttraining's rmse: 0.733028\tvalid_1's rmse: 0.914281\n",
      "[919]\ttraining's rmse: 0.732986\tvalid_1's rmse: 0.914272\n",
      "[920]\ttraining's rmse: 0.732947\tvalid_1's rmse: 0.914273\n",
      "[921]\ttraining's rmse: 0.73289\tvalid_1's rmse: 0.914262\n",
      "[922]\ttraining's rmse: 0.732848\tvalid_1's rmse: 0.914255\n",
      "[923]\ttraining's rmse: 0.732794\tvalid_1's rmse: 0.914287\n",
      "[924]\ttraining's rmse: 0.73275\tvalid_1's rmse: 0.914271\n",
      "[925]\ttraining's rmse: 0.732712\tvalid_1's rmse: 0.91427\n",
      "[926]\ttraining's rmse: 0.73267\tvalid_1's rmse: 0.914314\n",
      "[927]\ttraining's rmse: 0.732625\tvalid_1's rmse: 0.91432\n",
      "[928]\ttraining's rmse: 0.732587\tvalid_1's rmse: 0.914323\n",
      "[929]\ttraining's rmse: 0.73255\tvalid_1's rmse: 0.914317\n",
      "[930]\ttraining's rmse: 0.732505\tvalid_1's rmse: 0.914307\n",
      "[931]\ttraining's rmse: 0.732471\tvalid_1's rmse: 0.91434\n",
      "[932]\ttraining's rmse: 0.732431\tvalid_1's rmse: 0.914297\n",
      "[933]\ttraining's rmse: 0.732399\tvalid_1's rmse: 0.914298\n",
      "[934]\ttraining's rmse: 0.73236\tvalid_1's rmse: 0.914303\n",
      "[935]\ttraining's rmse: 0.732311\tvalid_1's rmse: 0.914308\n",
      "[936]\ttraining's rmse: 0.732253\tvalid_1's rmse: 0.914344\n",
      "[937]\ttraining's rmse: 0.732214\tvalid_1's rmse: 0.914337\n",
      "[938]\ttraining's rmse: 0.732167\tvalid_1's rmse: 0.914322\n",
      "[939]\ttraining's rmse: 0.732131\tvalid_1's rmse: 0.91431\n",
      "[940]\ttraining's rmse: 0.732076\tvalid_1's rmse: 0.914301\n",
      "[941]\ttraining's rmse: 0.732038\tvalid_1's rmse: 0.914304\n",
      "[942]\ttraining's rmse: 0.731991\tvalid_1's rmse: 0.914267\n",
      "[943]\ttraining's rmse: 0.731943\tvalid_1's rmse: 0.914276\n",
      "[944]\ttraining's rmse: 0.731901\tvalid_1's rmse: 0.914263\n",
      "[945]\ttraining's rmse: 0.73184\tvalid_1's rmse: 0.914253\n",
      "[946]\ttraining's rmse: 0.7318\tvalid_1's rmse: 0.914232\n",
      "[947]\ttraining's rmse: 0.731752\tvalid_1's rmse: 0.914229\n",
      "[948]\ttraining's rmse: 0.731683\tvalid_1's rmse: 0.914062\n",
      "[949]\ttraining's rmse: 0.731644\tvalid_1's rmse: 0.914065\n",
      "[950]\ttraining's rmse: 0.731603\tvalid_1's rmse: 0.914057\n",
      "[951]\ttraining's rmse: 0.731534\tvalid_1's rmse: 0.914066\n",
      "[952]\ttraining's rmse: 0.73149\tvalid_1's rmse: 0.914052\n",
      "[953]\ttraining's rmse: 0.731451\tvalid_1's rmse: 0.914055\n",
      "[954]\ttraining's rmse: 0.731409\tvalid_1's rmse: 0.914054\n",
      "[955]\ttraining's rmse: 0.731367\tvalid_1's rmse: 0.914026\n",
      "[956]\ttraining's rmse: 0.73133\tvalid_1's rmse: 0.914013\n",
      "[957]\ttraining's rmse: 0.731297\tvalid_1's rmse: 0.914016\n",
      "[958]\ttraining's rmse: 0.731236\tvalid_1's rmse: 0.913988\n",
      "[959]\ttraining's rmse: 0.731195\tvalid_1's rmse: 0.913984\n",
      "[960]\ttraining's rmse: 0.73115\tvalid_1's rmse: 0.913991\n",
      "[961]\ttraining's rmse: 0.73106\tvalid_1's rmse: 0.913953\n",
      "[962]\ttraining's rmse: 0.730989\tvalid_1's rmse: 0.913944\n",
      "[963]\ttraining's rmse: 0.73094\tvalid_1's rmse: 0.913945\n",
      "[964]\ttraining's rmse: 0.730857\tvalid_1's rmse: 0.913949\n",
      "[965]\ttraining's rmse: 0.730806\tvalid_1's rmse: 0.913972\n",
      "[966]\ttraining's rmse: 0.730773\tvalid_1's rmse: 0.913976\n",
      "[967]\ttraining's rmse: 0.730739\tvalid_1's rmse: 0.913977\n",
      "[968]\ttraining's rmse: 0.730698\tvalid_1's rmse: 0.913966\n",
      "[969]\ttraining's rmse: 0.730647\tvalid_1's rmse: 0.913955\n",
      "[970]\ttraining's rmse: 0.730603\tvalid_1's rmse: 0.913935\n",
      "[971]\ttraining's rmse: 0.730574\tvalid_1's rmse: 0.913931\n",
      "[972]\ttraining's rmse: 0.730536\tvalid_1's rmse: 0.913921\n",
      "[973]\ttraining's rmse: 0.730501\tvalid_1's rmse: 0.913918\n",
      "[974]\ttraining's rmse: 0.730462\tvalid_1's rmse: 0.913919\n",
      "[975]\ttraining's rmse: 0.730425\tvalid_1's rmse: 0.913914\n",
      "[976]\ttraining's rmse: 0.730386\tvalid_1's rmse: 0.913912\n",
      "[977]\ttraining's rmse: 0.730328\tvalid_1's rmse: 0.913882\n",
      "[978]\ttraining's rmse: 0.730277\tvalid_1's rmse: 0.913886\n",
      "[979]\ttraining's rmse: 0.730235\tvalid_1's rmse: 0.913897\n",
      "[980]\ttraining's rmse: 0.730195\tvalid_1's rmse: 0.913899\n",
      "[981]\ttraining's rmse: 0.73015\tvalid_1's rmse: 0.913909\n",
      "[982]\ttraining's rmse: 0.730093\tvalid_1's rmse: 0.9139\n",
      "[983]\ttraining's rmse: 0.730056\tvalid_1's rmse: 0.913899\n",
      "[984]\ttraining's rmse: 0.730014\tvalid_1's rmse: 0.913862\n",
      "[985]\ttraining's rmse: 0.729968\tvalid_1's rmse: 0.913859\n",
      "[986]\ttraining's rmse: 0.729938\tvalid_1's rmse: 0.913854\n",
      "[987]\ttraining's rmse: 0.7299\tvalid_1's rmse: 0.913882\n",
      "[988]\ttraining's rmse: 0.729801\tvalid_1's rmse: 0.913958\n",
      "[989]\ttraining's rmse: 0.729765\tvalid_1's rmse: 0.913964\n",
      "[990]\ttraining's rmse: 0.729735\tvalid_1's rmse: 0.913956\n",
      "[991]\ttraining's rmse: 0.729689\tvalid_1's rmse: 0.91396\n",
      "[992]\ttraining's rmse: 0.729658\tvalid_1's rmse: 0.913959\n",
      "[993]\ttraining's rmse: 0.729621\tvalid_1's rmse: 0.913966\n",
      "[994]\ttraining's rmse: 0.72956\tvalid_1's rmse: 0.913966\n",
      "[995]\ttraining's rmse: 0.729522\tvalid_1's rmse: 0.913959\n",
      "[996]\ttraining's rmse: 0.72948\tvalid_1's rmse: 0.913959\n",
      "[997]\ttraining's rmse: 0.729397\tvalid_1's rmse: 0.913959\n",
      "[998]\ttraining's rmse: 0.729363\tvalid_1's rmse: 0.913952\n",
      "[999]\ttraining's rmse: 0.729323\tvalid_1's rmse: 0.913936\n",
      "[1000]\ttraining's rmse: 0.729295\tvalid_1's rmse: 0.91393\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb.train(params, train_data, valid_sets=[train_data, valid_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>cat_type_code</th>\n",
       "      <th>cat_subtype_code</th>\n",
       "      <th>shop_city_code</th>\n",
       "      <th>shop_type_code</th>\n",
       "      <th>item_cnt_month_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>date_item_city_avg_item_cnt_lag_1</th>\n",
       "      <th>date_item_city_avg_item_cnt_lag_2</th>\n",
       "      <th>date_item_city_avg_item_cnt_lag_3</th>\n",
       "      <th>date_item_city_avg_item_cnt_lag_6</th>\n",
       "      <th>date_item_city_avg_item_cnt_lag_12</th>\n",
       "      <th>delta_price_lag</th>\n",
       "      <th>month</th>\n",
       "      <th>days</th>\n",
       "      <th>item_shop_first_sale</th>\n",
       "      <th>item_first_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4488756</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.282715</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488757</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.483398</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488758</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.137451</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488759</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.407227</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488760</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.225464</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128045</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>18454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.475098</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128046</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>16188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081116</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128047</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>15757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155884</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128048</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>19648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.091736</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128049</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.605957</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6639294 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date_block_num  shop_id  item_id  item_cnt_month  item_category_id  \\\n",
       "4488756               12        2       27             0.0                19   \n",
       "4488757               12        2       30             0.0                40   \n",
       "4488758               12        2       31             0.0                37   \n",
       "4488759               12        2       32             1.0                40   \n",
       "4488760               12        2       33             1.0                37   \n",
       "...                  ...      ...      ...             ...               ...   \n",
       "11128045              34       45    18454             0.0                55   \n",
       "11128046              34       45    16188             0.0                64   \n",
       "11128047              34       45    15757             0.0                55   \n",
       "11128048              34       45    19648             0.0                40   \n",
       "11128049              34       45      969             0.0                37   \n",
       "\n",
       "          cat_type_code  cat_subtype_code  shop_city_code  shop_type_code  \\\n",
       "4488756               5                10               1               4   \n",
       "4488757              11                 4               1               4   \n",
       "4488758              11                 1               1               4   \n",
       "4488759              11                 4               1               4   \n",
       "4488760              11                 1               1               4   \n",
       "...                 ...               ...             ...             ...   \n",
       "11128045             13                 2              21               4   \n",
       "11128046             14                42              21               4   \n",
       "11128047             13                 2              21               4   \n",
       "11128048             11                 4              21               4   \n",
       "11128049             11                 1              21               4   \n",
       "\n",
       "          item_cnt_month_lag_1  ...  date_item_city_avg_item_cnt_lag_1  \\\n",
       "4488756                    0.0  ...                                0.0   \n",
       "4488757                    0.0  ...                                0.0   \n",
       "4488758                    0.0  ...                                0.0   \n",
       "4488759                    0.0  ...                                0.0   \n",
       "4488760                    1.0  ...                                1.0   \n",
       "...                        ...  ...                                ...   \n",
       "11128045                   1.0  ...                                0.5   \n",
       "11128046                   0.0  ...                                0.0   \n",
       "11128047                   0.0  ...                                0.0   \n",
       "11128048                   0.0  ...                                0.0   \n",
       "11128049                   0.0  ...                                0.5   \n",
       "\n",
       "          date_item_city_avg_item_cnt_lag_2  \\\n",
       "4488756                                 0.0   \n",
       "4488757                                 0.0   \n",
       "4488758                                 0.0   \n",
       "4488759                                 0.0   \n",
       "4488760                                 2.0   \n",
       "...                                     ...   \n",
       "11128045                                0.0   \n",
       "11128046                                0.0   \n",
       "11128047                                0.5   \n",
       "11128048                                0.0   \n",
       "11128049                                0.0   \n",
       "\n",
       "          date_item_city_avg_item_cnt_lag_3  \\\n",
       "4488756                                 0.0   \n",
       "4488757                                 0.0   \n",
       "4488758                                 0.0   \n",
       "4488759                                 0.0   \n",
       "4488760                                 0.0   \n",
       "...                                     ...   \n",
       "11128045                                0.0   \n",
       "11128046                                0.0   \n",
       "11128047                                0.0   \n",
       "11128048                                0.0   \n",
       "11128049                                0.0   \n",
       "\n",
       "          date_item_city_avg_item_cnt_lag_6  \\\n",
       "4488756                                 0.0   \n",
       "4488757                                 0.0   \n",
       "4488758                                 0.0   \n",
       "4488759                                 0.0   \n",
       "4488760                                 0.0   \n",
       "...                                     ...   \n",
       "11128045                                0.0   \n",
       "11128046                                0.0   \n",
       "11128047                                0.0   \n",
       "11128048                                0.0   \n",
       "11128049                                0.0   \n",
       "\n",
       "          date_item_city_avg_item_cnt_lag_12  delta_price_lag  month  days  \\\n",
       "4488756                                  1.0        -0.282715      0    31   \n",
       "4488757                                  0.0        -0.483398      0    31   \n",
       "4488758                                  0.0        -0.137451      0    31   \n",
       "4488759                                  0.0        -0.407227      0    31   \n",
       "4488760                                  1.0        -0.225464      0    31   \n",
       "...                                      ...              ...    ...   ...   \n",
       "11128045                                 0.0        -0.475098     10    30   \n",
       "11128046                                 0.0         0.081116     10    30   \n",
       "11128047                                 0.0         0.155884     10    30   \n",
       "11128048                                 0.0        -0.091736     10    30   \n",
       "11128049                                 0.0        -0.605957     10    30   \n",
       "\n",
       "          item_shop_first_sale  item_first_sale  \n",
       "4488756                     12               12  \n",
       "4488757                     11               11  \n",
       "4488758                     11               11  \n",
       "4488759                     12               12  \n",
       "4488760                     12               12  \n",
       "...                        ...              ...  \n",
       "11128045                    11               11  \n",
       "11128046                     2                2  \n",
       "11128047                    34               34  \n",
       "11128048                    11               11  \n",
       "11128049                    17               17  \n",
       "\n",
       "[6639294 rows x 64 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = matrix[matrix['date_block_num'] == 34]\n",
    "# label_test = testData['item_cnt_month']\n",
    "X_test = testData.drop('item_cnt_month', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62966215, 0.41539438, 1.35523091, ..., 0.04768919, 0.02385558,\n",
       "       0.03641442])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = lgb_model.predict(X_test).clip(0, 20)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214195</th>\n",
       "      <td>214195</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214196</th>\n",
       "      <td>214196</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214197</th>\n",
       "      <td>214197</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214198</th>\n",
       "      <td>214198</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214199</th>\n",
       "      <td>214199</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  item_cnt_month\n",
       "0            0             0.5\n",
       "1            1             0.5\n",
       "2            2             0.5\n",
       "3            3             0.5\n",
       "4            4             0.5\n",
       "...        ...             ...\n",
       "214195  214195             0.5\n",
       "214196  214196             0.5\n",
       "214197  214197             0.5\n",
       "214198  214198             0.5\n",
       "214199  214199             0.5\n",
       "\n",
       "[214200 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = pd.read_csv('./data/sample_submission.csv')\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214200 entries, 0 to 214199\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   ID              214200 non-null  int64  \n",
      " 1   item_cnt_month  214200 non-null  float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "ss.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.629662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.415394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.355231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.525864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.359572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214195</th>\n",
       "      <td>214195</td>\n",
       "      <td>0.088922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214196</th>\n",
       "      <td>214196</td>\n",
       "      <td>0.037873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214197</th>\n",
       "      <td>214197</td>\n",
       "      <td>0.047689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214198</th>\n",
       "      <td>214198</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214199</th>\n",
       "      <td>214199</td>\n",
       "      <td>0.036414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  item_cnt_month\n",
       "0            0        0.629662\n",
       "1            1        0.415394\n",
       "2            2        1.355231\n",
       "3            3        0.525864\n",
       "4            4        2.359572\n",
       "...        ...             ...\n",
       "214195  214195        0.088922\n",
       "214196  214196        0.037873\n",
       "214197  214197        0.047689\n",
       "214198  214198        0.023856\n",
       "214199  214199        0.036414\n",
       "\n",
       "[214200 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({ 'ID': range(0, 214200), 'item_cnt_month': y_test})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submit/sub2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214200 entries, 0 to 214199\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   ID              214200 non-null  int64  \n",
      " 1   item_cnt_month  214200 non-null  float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
